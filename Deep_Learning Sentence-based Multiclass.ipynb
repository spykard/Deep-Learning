{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_Learning Sentence-based Multiclass.ipynb","provenance":[],"collapsed_sections":["h_bOJoy2dh2S"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h_bOJoy2dh2S","colab_type":"text"},"source":["### Temporary Code until new Keras release comes out"]},{"cell_type":"code","metadata":{"id":"eS6EjShkdhf5","colab_type":"code","colab":{}},"source":["\"\"\"IMDB sentiment classification dataset.\n","\"\"\"\n","from keras.utils.data_utils import get_file\n","from keras.preprocessing.sequence import _remove_long_seq\n","import numpy as np\n","import json\n","import warnings\n","\n","class imdb:\n","    def load_data(path='imdb.npz', num_words=None, skip_top=0,\n","                  maxlen=None, seed=113,\n","                  start_char=1, oov_char=2, index_from=3, **kwargs):\n","        \"\"\"Loads the IMDB dataset.\n","        # Arguments\n","            path: where to cache the data (relative to `~/.keras/dataset`).\n","            num_words: max number of words to include. Words are ranked\n","                by how often they occur (in the training set) and only\n","                the most frequent words are kept\n","            skip_top: skip the top N most frequently occurring words\n","                (which may not be informative).\n","            maxlen: sequences longer than this will be filtered out.\n","            seed: random seed for sample shuffling.\n","            start_char: The start of a sequence will be marked with this character.\n","                Set to 1 because 0 is usually the padding character.\n","            oov_char: words that were cut out because of the `num_words`\n","                or `skip_top` limit will be replaced with this character.\n","            index_from: index actual words with this index and higher.\n","        # Returns\n","            Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n","        # Raises\n","            ValueError: in case `maxlen` is so low\n","                that no input sequence could be kept.\n","        Note that the 'out of vocabulary' character is only used for\n","        words that were present in the training set but are not included\n","        because they're not making the `num_words` cut here.\n","        Words that were not seen in the training set but are in the test set\n","        have simply been skipped.\n","        \"\"\"\n","        # Legacy support\n","        if 'nb_words' in kwargs:\n","            warnings.warn('The `nb_words` argument in `load_data` '\n","                          'has been renamed `num_words`.')\n","            num_words = kwargs.pop('nb_words')\n","        if kwargs:\n","            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n","\n","        path = get_file(path,\n","                        origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n","                        file_hash='599dadb1135973df5b59232a0e9a887c')\n","        with np.load(path, allow_pickle=True) as f:\n","            x_train, labels_train = f['x_train'], f['y_train']\n","            x_test, labels_test = f['x_test'], f['y_test']\n","\n","        rng = np.random.RandomState(seed)\n","        indices = np.arange(len(x_train))\n","        rng.shuffle(indices)\n","        x_train = x_train[indices]\n","        labels_train = labels_train[indices]\n","\n","        indices = np.arange(len(x_test))\n","        rng.shuffle(indices)\n","        x_test = x_test[indices]\n","        labels_test = labels_test[indices]\n","\n","        xs = np.concatenate([x_train, x_test])\n","        labels = np.concatenate([labels_train, labels_test])\n","\n","        if start_char is not None:\n","            xs = [[start_char] + [w + index_from for w in x] for x in xs]\n","        elif index_from:\n","            xs = [[w + index_from for w in x] for x in xs]\n","\n","        if maxlen:\n","            xs, labels = _remove_long_seq(maxlen, xs, labels)\n","            if not xs:\n","                raise ValueError('After filtering for sequences shorter than maxlen=' +\n","                                 str(maxlen) + ', no sequence was kept. '\n","                                 'Increase maxlen.')\n","        if not num_words:\n","            num_words = max([max(x) for x in xs])\n","\n","        # by convention, use 2 as OOV word\n","        # reserve 'index_from' (=3 by default) characters:\n","        # 0 (padding), 1 (start), 2 (OOV)\n","        if oov_char is not None:\n","            xs = [[w if (skip_top <= w < num_words) else oov_char for w in x]\n","                  for x in xs]\n","        else:\n","            xs = [[w for w in x if skip_top <= w < num_words]\n","                  for x in xs]\n","\n","        idx = len(x_train)\n","        x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n","        x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n","\n","        return (x_train, y_train), (x_test, y_test)\n","\n","\n","    def get_word_index(path='imdb_word_index.json'):\n","        \"\"\"Retrieves the dictionary mapping words to word indices.\n","        # Arguments\n","            path: where to cache the data (relative to `~/.keras/dataset`).\n","        # Returns\n","            The word index dictionary.\n","        \"\"\"\n","        path = get_file(\n","            path,\n","            origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n","            file_hash='bfafd718b763782e994055a2d397834f')\n","        with open(path) as f:\n","            return json.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNONFRCwckat","colab_type":"text"},"source":["## Base Code"]},{"cell_type":"markdown","metadata":{"id":"a4SV90uyrkVM","colab_type":"text"},"source":["### Prerequisites\n","\n","Python 3.6+ is required because of certain performance optimization steps, such as the use of f-strings.  \n","GPU usage is required, e.g. the LSTM layers are specific CuDNN ones."]},{"cell_type":"code","metadata":{"id":"p-tM81VCqi14","colab_type":"code","cellView":"both","outputId":"dd66f300-31ed-44f2-84f9-f210ff5e826b","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1568763911965,"user_tz":-180,"elapsed":4771,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["### Parameters ###\n","use_google_drive = True #@param {type:\"boolean\"}\n","gpu_fraction_usage = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n","###            ###\n","\n","# Upgrade gensim package\n","!pip install gensim --upgrade --quiet\n","\n","# Connect to Google Drive via the bundled client which is the simplest out of many approaches\n","if use_google_drive == True:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","# GPU usage settings for Tensorflow backend\n","from tensorflow import ConfigProto, Session\n","from keras import backend as K\n","if K.backend() == \"tensorflow\":\n","    from keras.backend.tensorflow_backend import set_session\n","    config = ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction_usage\n","    set_session(Session(config=config))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"D4gscjCDrsK_","colab_type":"text"},"source":["### Run"]},{"cell_type":"code","metadata":{"id":"7deMX4jmcy50","colab_type":"code","cellView":"both","outputId":"b97ae9ff-1f79-40f8-a90d-50c26eeed742","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1568768077517,"user_tz":-180,"elapsed":773,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["import keras\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Embedding, LSTM, CuDNNLSTM, Bidirectional, Dropout, GlobalAveragePooling1D, SimpleRNN, GRU, Conv1D\n","from keras.optimizers import Adam, SGD, Adagrad\n","from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n","from keras.utils import np_utils\n","from gensim.models import Word2Vec, KeyedVectors\n","from sklearn.model_selection import train_test_split\n","###            ###\n","import numpy as np\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","from IPython.display import SVG\n","###            ###\n","import random\n","from tensorflow import set_random_seed\n","\n","### Parameters ###\n","random_state = 22 #@param {type:\"slider\", min:0, max:100, step:1}\n","dataset_name = \"Finegrained Sentiment Dataset\" #@param [\"IMDb Large Movie Review Dataset\", \"Movie Review Subjectivity Dataset\", \"Movie Review Polarity Dataset\", \"Finegrained Sentiment Dataset\"]\n","feature_count = 4 #@param {type:\"slider\", min:0, max:50000, step:1}\n","###            ###\n","\n","# Reproducibility\n","random.seed(random_state)  # Python's seed\n","np.random.seed(random_state)  # Numpy's seed\n","if K.backend() == \"tensorflow\":\n","    set_random_seed(random_state)  # Tensorflow's seed\n","\n","# Load Dataset\n","if dataset_name == \"IMDb Large Movie Review Dataset\":\n","    #imdb = keras.datasets.imdb  # TEMPORARY FIX\n","    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(seed=random_state, num_words=feature_count)\n","elif dataset_name == \"Movie Review Subjectivity Dataset\":\n","    data = [\"\" for i in range(10000)]\n","    labels = [\"\" for i in range(10000)]\n","    count = 0\n","    with open('./gdrive/My Drive/Colab Datasets/Movie Review Subjectivity Dataset/plot.tok.gt9.5000', 'r', encoding='iso-8859-15') as file:\n","        for line in file:\n","            data[count] = line.rstrip('\\n')\n","            labels[count] = 0\n","            count += 1\n","    with open('./gdrive/My Drive/Colab Datasets/Movie Review Subjectivity Dataset/quote.tok.gt9.5000', 'r', encoding='iso-8859-15') as file:\n","        for line in file:\n","            data[count] = line.rstrip('\\n')\n","            labels[count] = 1\n","            count += 1   \n","    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.1, random_state=random_state, shuffle=True)   \n","    del data, labels\n","elif dataset_name == \"Movie Review Polarity Dataset\":\n","    data = [\"\" for i in range(10662)]\n","    labels = [\"\" for i in range(10662)]\n","    count = 0\n","    with open('./gdrive/My Drive/Colab Datasets/Movie Review Polarity Dataset/rt-polarity.neg', 'r', encoding='iso-8859-15') as file:\n","        for line in file:\n","            data[count] = line.rstrip('\\n')\n","            labels[count] = 0\n","            count += 1\n","    with open('./gdrive/My Drive/Colab Datasets/Movie Review Polarity Dataset/rt-polarity.pos', 'r', encoding='iso-8859-15') as file:\n","        for line in file:\n","            data[count] = line.rstrip('\\n')\n","            labels[count] = 1\n","            count += 1    \n","    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.1, random_state=random_state, shuffle=True)   \n","    del data, labels   \n","else:\n","    # Finegrained goes here\n","    data = [[] for i in range(294)]\n","    labels = [\"\" for i in range(294)]\n","    count = 0\n","    #with open('./Datasets/Finegrained/finegrained.txt', 'r') as file:\n","    with open('./gdrive/My Drive/Colab Datasets/Finegrained Sentiment Dataset/finegrained.txt', 'r', encoding='iso-8859-15') as file:\n","        for line in file:\n","            if len(line.split(\"_\")) == 3:\n","                labels[count] = line.split(\"_\")[1]                  \n","            elif len(line.strip()) == 0:\n","                data[count] = ' '.join(data[count])\n","                count += 1\n","            else:\n","                temp = [x.strip() for x in line.split(\"\\t\")]\n","                if len(temp[1]) > 1:\n","                    # \"nr\" label is ignored\n","                    if temp[0] in [\"neg\", \"neu\", \"pos\", \"mix\"]:\n","                        data[count].append(temp[0])              \n","    \n","    from sklearn.preprocessing import LabelEncoder\n","    encoder = LabelEncoder()\n","    encoder.fit(labels)\n","    encoded_Y = encoder.transform(labels)\n","    # Convert integers to one-hot encoding\n","    labels = np_utils.to_categorical(encoded_Y)\n","        \n","    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=random_state, shuffle=True)   \n","    del data, labels \n","                     \n","    \n","print(f\"Training entries: {len(train_data)}, labels: {len(train_labels)}\")\n","if dataset_name == \"IMDb Large Movie Review Dataset\":\n","    print(train_data[0:4])\n","else:\n","    for i in range(4): print(train_data[i])"],"execution_count":111,"outputs":[{"output_type":"stream","text":["Training entries: 235, labels: 235\n","pos neu pos neg pos neg neu pos pos\n","pos pos pos\n","mix neu pos pos pos neg neg neg neg neg neg neg neg neg neg neg neg neg neu\n","pos pos pos\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y2AsF2mN2Mz5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0b6dcf95-63d4-4276-a5be-54d06dde678c","executionInfo":{"status":"ok","timestamp":1568767805438,"user_tz":-180,"elapsed":657,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["print(train_labels[0:4], type(train_labels[0:4]))"],"execution_count":103,"outputs":[{"output_type":"stream","text":["[3, 2, 3, 2] <class 'list'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6V0jAQMrj6eU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"5dacd293-5bfb-4f09-9024-441e7482dcc9","executionInfo":{"status":"ok","timestamp":1568768081110,"user_tz":-180,"elapsed":1002,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["print(train_labels[0:4], type(train_labels[0:4]))\n"],"execution_count":112,"outputs":[{"output_type":"stream","text":["[[0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]] <class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ieVaHvUherqc","colab_type":"code","colab":{}},"source":["def imdb_specific_word_index():\n","    # A dictionary mapping words to an integer index\n","    word_index = imdb.get_word_index()\n","\n","    # The first indices are reserved\n","    word_index = {k:(v+3) for k,v in word_index.items()}\n","    #word_index[\"<PAD>\"] = 0  # not inserting this key makes the word_index have the same length as in non-IMDb datasets, i.e. for 20000 features we end up with a length of 19999\n","    word_index[\"<START>\"] = 1\n","    word_index[\"<UNK>\"] = 2  # unknown/oov word\n","    word_index[\"<UNUSED>\"] = 3\n","\n","    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","    \n","    return (word_index, reverse_word_index)\n","    \n","def other_datasets_word_index(tokenizer):\n","    # A dictionary mapping words to an integer index\n","    word_index = tokenizer.word_index\n","    \n","    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","    \n","    return (word_index, reverse_word_index)\n","\n","def print_dataset_length_stats():        \n","    maxim = 0\n","    total = 0\n","    count = 0\n","    for i in train_data:\n","        length = len(i)\n","        if length > maxim:\n","            maxim = length\n","        count += 1\n","        total += length\n","    print(f\"\\nGeneral stats regarding the length of instances of the dataset (to help choose embeddings_sequence_length) - avg:{total/count} max:{maxim}\\n\")\n","\n","def decode_review(text, reverse_word_index, mode):\n","    if mode == \"join\":\n","        return ' '.join([reverse_word_index.get(i, '?') for i in text])\n","    else:\n","        return [reverse_word_index.get(i, '?') for i in text]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCFF9vWhvURq","colab_type":"text"},"source":["**Regarding Word2Vec, Embeddings and Google Drive**\n","\n","Converting the Word2Vec bin file to a text file of bigger size is even worse since we are using Google Drive.  \n","Ideally the Google Drive file must be as small as possible because the bottleneck is caused by Download Speed not by the loading process itself.\n","\n","Location: USA  \n","Download: 134.43 Mbit/s  \n","Upload: 178.00 Mbit/s\n","\n","Load time for the zipped file is 170 to 293 seconds.\n","\n","---\n","\n","So here is a great idea: download the file from Drive to Colab [[1](https://stackoverflow.com/questions/48735600/file-download-from-google-drive-to-colaboratory)] [[2](https://medium.freecodecamp.org/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa)] at the very start so that we can maintain access for the entire Runtime.\n","\n","Download time is 73 to 80 seconds.\n","\n","---\n","\n","**Regarding alternatives of Word2Vec**\n","\n","FastText is simply Word2Vec with subword n-grams but requires more RAM and training time\n","\n","---\n","\n","**Regarding simple Word2Vec similarity Examples on line 25**\n","\n","Other than the 3.6GB of RAM that we are using to load the Word2Vec embeddings, using simple similarity examples on the model to ensure its working will lead to an extra 3.6GB being used [[1](https://stackoverflow.com/questions/50478046/memory-error-when-using-gensim-for-loading-word2vec)] [[2](https://github.com/RaRe-Technologies/gensim/issues/293#issuecomment-175026483)].  \n","\"I can load the model fine, and can retrieve the word vectors of words fine, but it seems to explode just when I try to access similarity-related functions (including 'doesn't match') etc.\"  \n","\n","If you want to enable the similarity examples, change line 25."]},{"cell_type":"code","metadata":{"id":"ELXD0oIBDU0z","colab_type":"code","colab":{}},"source":["def load_word2vec_pretrained():  # Used later on\n","    time_counter = time.time()\n","    print(f\"Downloading data from Google Drive to Colab hard drive...\")\n","    !mkdir my_data\n","    !cp -i '/content/gdrive/My Drive/Colab Datasets/GoogleNews-vectors-negative300.bin.gz' '/content/my_data/GoogleNews-vectors-negative300.bin.gz'\n","    print(f\"Download completed in {time.time()-time_counter:.2f}sec, displaying information\")\n","    !ls '/content/my_data' -l --block-size=MB\n","\n","    time_counter = time.time()\n","    print(f\"Loading file...\")\n","    word2vec = KeyedVectors.load_word2vec_format('/content/my_data/GoogleNews-vectors-negative300.bin.gz', binary=True, unicode_errors='strict')    \n","    print(f\"Loading completed in {time.time()-time_counter:.2f}sec\")\n","    \n","    # Download & Unzip\n","    # word2vec = gzip.open('/content/gdrive/My Drive/Colab Datasets/GoogleNews-vectors-negative300.bin.gz', 'rb')\n","\n","    # Followed by: Convert from bin to text file & Upload\n","    # word2vec.save_word2vec_format('/content/gdrive/My Drive/Colab Datasets/GoogleNews-vectors-negative300.txt', binary=False)\n","    # word2vec_text_mode = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Colab Datasets/GoogleNews-vectors-negative300.txt')    \n","    \n","    dog = word2vec['dog']\n","    print(f\"\\nWord2Vec Embeddings Dimension: {dog.shape}\")\n","    print(f\"Example Values: {dog[:10]}\")\n","    \n","    if False:\n","        # Some predefined functions that show content related information for given words\n","        print(f\"Test 1: {word2vec.most_similar(positive=['woman', 'king'], negative=['man'])}\")\n","        print(f\"Test 2: {word2vec.most_similar('hyundai', topn=10)}\")\n","        print(f\"Test 3: {word2vec.doesnt_match('breakfast cereal dinner lunch'.split())}\")  # Raises Warning\n","        print(f\"Test 4: {word2vec.similarity('woman', 'man')}\")\n","    else:\n","        print(f\"Examples of Word2Vec and similarity function usage won't be run in order to preserve RAM.\")\n","        \n","    return word2vec\n","\n","def manage_oov_words(embeddings, vocab):\n","    # Find words in common, meaning the remaining ones are out-of-vocabulary (OOV) ones    \n","    words_oov = set(filter(lambda x: x not in embeddings.vocab, vocab))  # filter is not a good format, if the variable is used once it becomes empty (i.e. a generator), use set instead\n","    print(f\"Impossible to remove all occurances of {len(words_oov)} words since time complexity would be too high. Out-of-vocabulary words will be kept and will be assigned vectors...\")\n","    if len(words_oov) >= 3:\n","        to_print = iter(words_oov)\n","        print(f\"Some examples: {next(to_print)}, {next(to_print)}, {next(to_print)}\")\n","    \n","    #encoding_oov = [vocab[word] for word in words_oov]\n","    #for instance in data_container:\n","        #[word for word in instance if word not in encoding_oov]  # looking up a set is the absolute fastest in python\n","\n","def assign_embeddings(embeddings, embeddings_dimension, vocab, mode):\n","    ''' Create an embeddings (weight) matrix for the Embedding layer from a loaded embedding '''\n","    # Find words in common, meaning the remaining ones are out-of-vocabulary (OOV) ones    \n","    words_in_common = set(filter(lambda x: x in embeddings.vocab, vocab))  # filter is not a good format, if the variable is used once it becomes empty (i.e. a generator), use set instead\n","    words_oov = set(filter(lambda x: x not in embeddings.vocab, vocab))  # filter is not a good format, if the variable is used once it becomes empty (i.e. a generator), use set instead\n","    print(f\"Number of vocabulary words that cannot be found in the Word2Vec embeddings: {len(words_oov)}\")  \n","    \n","    # \"Total vocabulary size plus 0 for unknown words 'len(vocab) + 1\" is not entirely true, the index of 0 is simply not used leading to, for example a length of 19999 for 20000 features:\n","    vocab_size = len(vocab) + 1\n","    # Initialize the weight matrix with 0s\n","    embed_final_matrix = np.zeros((vocab_size, embeddings_dimension))\n","    # Store vectors using an integer mapping, for example from the Tokenizer\n","    \n","    if mode == \"zeros\":\n","        for word in words_in_common:\n","            embed_final_matrix[vocab[word]] = embeddings[word]\n","    elif mode == \"random\":\n","        np.random.seed(random_state)\n","        for word, i in vocab.items():\n","            if word in words_oov:\n","                embed_final_matrix[i] = np.random.uniform(low=-0.5, high=0.5, size=embeddings_dimension)\n","            else:\n","                embed_final_matrix[i] = embeddings[word]\n","    else:\n","        raise ValueError(f\"{mode} is not a valid mode parameter.\")\n","    \n","    print(f\"Embeddings assignment completed.\\n\")      \n","    return embed_final_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSXVfstpijGg","colab_type":"code","cellView":"both","outputId":"fe11d2a5-f452-4ae5-9683-b869aae0e5f8","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1568768118447,"user_tz":-180,"elapsed":1382,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["### Parameters ###\n","remove_first = False #@param {type:\"boolean\"}\n","embeddings_mode = \"One-hot Encoding\" #@param [\"One-hot Encoding\", \"Tokenizing\", \"Word2Vec Pretrained\", \"Word2Vec Training\"]\n","embeddings_sequence_length = 24 #@param {type:\"integer\"}\n","trainable = True #@param {type:\"boolean\"}\n","outofvocab_mode = \"random\" #@param [\"zeros\", \"random\"]\n","###            ###\n","\n","# Remove the <START> symbol from all instances\n","if remove_first == True:\n","    if train_data[0][0] == word_index[\"<START>\"]:\n","        for i in range(len(train_data)):\n","            train_data[i] = train_data[i][1:]\n","        for i in range(len(test_data)):\n","            test_data[i] = test_data[i][1:]\n","            \n","if embeddings_mode == \"One-hot Encoding\":  \n","    ''' Description: Not traditional One-hot, but instead [3, 62, 5, 90, ...] \n","        Embedding_Layer: Yes\n","    '''   \n","    if dataset_name != \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded\n","        tokenizer = keras.preprocessing.text.Tokenizer(num_words=feature_count, \n","                                                       lower=True, \n","                                                       split=' ', \n","                                                       oov_token=\"<UNK>\")\n","        tokenizer.fit_on_texts(train_data)\n","        # 'texts_to_sequences' list of strings as input and sequence of integers as output, 'texts_to_matrix' is meant to return a matrix of counts/tf-idfs\n","        train_data = tokenizer.texts_to_sequences(train_data)\n","        test_data = tokenizer.texts_to_sequences(test_data)   \n","    \n","    # Word_Index Stuff\n","    if dataset_name == \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded\n","        (word_index, reverse_word_index) = imdb_specific_word_index()\n","    else:\n","        (word_index, reverse_word_index) = other_datasets_word_index(tokenizer)\n","\n","    ### Update the word index from its generic version to one that matches the number of features we loaded        \n","    word_index = {k: v for k, v in word_index.items() if v < feature_count} \n","    reverse_word_index = {k: v for k, v in reverse_word_index.items() if k < feature_count}  \n","    print(\"\\n\".join([decode_review(instance, reverse_word_index, mode=\"join\") for instance in train_data[0:4]]))\n","    print_dataset_length_stats()\n","    \n","    # Peform Sequence Padding\n","    ### Using 'pre' instead of 'post' on truncating leads to higher accuracy\n","    train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n","                                                            padding='pre',\n","                                                            truncating='pre',\n","                                                            maxlen=embeddings_sequence_length)\n","\n","    test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n","                                                           padding='pre',\n","                                                           truncating='pre',\n","                                                           maxlen=embeddings_sequence_length)\n","\n","elif embeddings_mode == \"Tokenizing\":  \n","    ''' Description: Unlike other modes this isn't exactly an embedding, leads to a collection of floats [0.00, 0.02, 0.12, 0.04, ...] \n","        Embedding_Layer: No\n","    '''    \n","    if dataset_name == \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded so let's transform it back to text\n","        (word_index, reverse_word_index) = imdb_specific_word_index()\n","        train_data = [decode_review(instance, reverse_word_index, mode=\"join\") for instance in train_data]\n","        test_data = [decode_review(instance, reverse_word_index, mode=\"join\") for instance in test_data]\n","    \n","    tokenizer = keras.preprocessing.text.Tokenizer(num_words=feature_count, \n","                                                   lower=True, \n","                                                   split=' ', \n","                                                   )\n","    tokenizer.fit_on_texts(train_data)\n","    # 'texts_to_matrix' list of strings as input, 'sequences_to_matrix' list of integer word indices as input \n","    train_data = tokenizer.texts_to_matrix(train_data, mode='tfidf')\n","    test_data = tokenizer.texts_to_matrix(test_data, mode='tfidf')\n","\n","elif embeddings_mode == \"Word2Vec Pretrained\":\n","    ''' Description: A much more advanced form of embeddings that is created through training a model unlike previous modes. Implements the CBOW and the Skip-gram models in order to learn word embeddings.\n","        Embedding_Layer: Yes\n","    '''\n","    word2vec = load_word2vec_pretrained()  # This line can be commented out, if it was already loaded in the current session\n","    embeddings_dimension = word2vec.vector_size\n","    \n","    if dataset_name != \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded\n","        tokenizer = keras.preprocessing.text.Tokenizer(num_words=feature_count, \n","                                                       lower=True, \n","                                                       split=' ', \n","                                                       oov_token=\"<UNK>\")\n","        tokenizer.fit_on_texts(train_data)\n","        # 'texts_to_sequences' list of strings as input and sequence of integers as output, 'texts_to_matrix' is meant to return a matrix of counts/tf-idfs\n","        train_data = tokenizer.texts_to_sequences(train_data)\n","        test_data = tokenizer.texts_to_sequences(test_data)   \n","    \n","    # Word_Index Stuff\n","    if dataset_name == \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded\n","        (word_index, reverse_word_index) = imdb_specific_word_index()\n","    else:\n","        (word_index, reverse_word_index) = other_datasets_word_index(tokenizer)\n","\n","    ### Update the word index from its generic version to one that matches the number of features we loaded        \n","    word_index = {k: v for k, v in word_index.items() if v < feature_count} \n","    reverse_word_index = {k: v for k, v in reverse_word_index.items() if k < feature_count}  \n","    print(\"\\n\".join([decode_review(instance, reverse_word_index, mode=\"join\") for instance in train_data[0:4]]))\n","    print_dataset_length_stats()\n","     \n","    # Peform Sequence Padding\n","    ### Using 'pre' instead of 'post' on truncating leads to higher accuracy\n","    train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n","                                                            padding='pre',\n","                                                            truncating='pre',\n","                                                            maxlen=embeddings_sequence_length)\n","\n","    test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n","                                                           padding='pre',\n","                                                           truncating='pre',\n","                                                           maxlen=embeddings_sequence_length)      \n","\n","    manage_oov_words(word2vec, word_index)\n","    \n","    embedding_vectors = assign_embeddings(word2vec, embeddings_dimension, word_index, mode=outofvocab_mode)\n","\n","elif embeddings_mode == \"Word2Vec Training\":\n","    ''' Description: A much more advanced form of embeddings that is created through training a model unlike previous modes. Implements the CBOW and the Skip-gram models in order to learn word embeddings.\n","        Embedding_Layer: Yes\n","    '''\n","    if dataset_name != \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded so let's transform it back to text\n","        #(word_index, reverse_word_index) = imdb_specific_word_index()\n","        #train_data = [decode_review(instance, reverse_word_index, mode=\"don't join\") for instance in train_data]\n","        #test_data = [decode_review(instance, reverse_word_index, mode=\"don't join\") for instance in test_data]    \n","        tokenizer = keras.preprocessing.text.Tokenizer(num_words=feature_count, \n","                                                       lower=True, \n","                                                       split=' ', \n","                                                       oov_token=\"<UNK>\")\n","        tokenizer.fit_on_texts(train_data)\n","        # 'texts_to_sequences' list of strings as input and sequence of integers as output, 'texts_to_matrix' is meant to return a matrix of counts/tf-idfs\n","        train_data = tokenizer.texts_to_sequences(train_data)\n","        test_data = tokenizer.texts_to_sequences(test_data)  \n","        \n","    # Word_Index Stuff\n","    if dataset_name == \"IMDb Large Movie Review Dataset\":  # keras.imdb is already One-hot Encoded so let's transform it back to text\n","        (word_index, reverse_word_index) = imdb_specific_word_index()\n","    else:\n","        (word_index, reverse_word_index) = other_datasets_word_index(tokenizer)\n","\n","    ### Update the word index from its generic version to one that matches the number of features we loaded        \n","    word_index = {k: v for k, v in word_index.items() if v < feature_count} \n","    reverse_word_index = {k: v for k, v in reverse_word_index.items() if k < feature_count}  \n","    print(\"\\n\".join([decode_review(instance, reverse_word_index, mode=\"join\") for instance in train_data[0:4]]))\n","    print_dataset_length_stats()        \n","        \n","    # Train a Model\n","    time_counter = time.time()    \n","    print(f\"Training a new custom Word2Vec model on the dataset...\")\n","    word2vec = Word2Vec([decode_review(instance, reverse_word_index, mode=\"don't join\") for instance in train_data],  # Default is 5 epochs \n","                         size=300, sg=0, window=5, min_count=1, iter=5,\n","                         seed=random_state, alpha=0.025, workers=4)\n","    embeddings_dimension = word2vec.wv.vector_size\n","    print(f\"Training completed in {time.time()-time_counter:.2f}sec. Vocabulary size: {len(word2vec.wv.vocab)}\\n\")  \n","\n","    # Peform Sequence Padding\n","    ### Using 'pre' instead of 'post' on truncating leads to higher accuracy\n","    train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n","                                                            padding='pre',\n","                                                            truncating='pre',\n","                                                            maxlen=embeddings_sequence_length)\n","\n","    test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n","                                                           padding='pre',\n","                                                           truncating='pre',\n","                                                           maxlen=embeddings_sequence_length)  \n","    \n","    manage_oov_words(word2vec.wv, word_index)\n","    \n","    embedding_vectors = assign_embeddings(word2vec.wv, embeddings_dimension, word_index, mode=outofvocab_mode)    \n","    \n","    # If we want to store the model\n","    # model.wv.save_word2vec_format(\"My_Word2Vec.txt\", binary=False)    \n","        \n","for i in range(4): print(type(train_data[i]), list(train_data[i]))"],"execution_count":113,"outputs":[{"output_type":"stream","text":["pos <UNK> pos neg pos neg <UNK> pos pos\n","pos pos pos\n","<UNK> <UNK> pos pos pos neg neg neg neg neg neg neg neg neg neg neg neg neg <UNK>\n","pos pos pos\n","\n","General stats regarding the length of instances of the dataset (to help choose embeddings_sequence_length) - avg:9.340425531914894 max:65\n","\n","<class 'numpy.ndarray'> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 3, 2, 3, 2, 1, 3, 3]\n","<class 'numpy.ndarray'> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3]\n","<class 'numpy.ndarray'> [0, 0, 0, 0, 0, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n","<class 'numpy.ndarray'> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N3LnBweojkLv","colab_type":"code","outputId":"81aa5763-e573-45fd-b1dc-c139154c0463","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1568768826906,"user_tz":-180,"elapsed":1155,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["# Input shape is equal to the vocabulary count\n","if embeddings_mode == \"Tokenizing\" or dataset_name == \"Finegrained Sentiment Dataset\":\n","    model = Sequential()\n","    model.add(Dense(units=6, input_shape=(24,)))  # when Embedding layer is not used, the first layer must include the input_shape parameter\n","    model.add(Dense(units=64, activation='relu', use_bias=True))\n","    #model.add(Dense(units=64, activation='relu', use_bias=True))\n","    model.add(Dense(3, activation='softmax'))  # the value of 1 doesn't refer to the neuron count, e.g. for multi-class it refers to the number of categories\n","\n","elif embeddings_mode == \"One-hot Encoding\":\n","    model = Sequential()\n","    model.add(Embedding(input_dim=feature_count, output_dim=16, input_length=embeddings_sequence_length))  \n","    model.add(GlobalAveragePooling1D()) \n","    model.add(Dense(units=16, activation='relu', use_bias=True))\n","    model.add(Dense(units=16, activation='relu', use_bias=True))\n","    model.add(Dense(1, activation='sigmoid'))  # the value of 1 doesn't refer to the neuron count, e.g. for multi-class it refers to the number of categories\n","\n","else:  # Word2Vec/GloVe Embeddings\n","    model = Sequential()\n","    model.add(Embedding(input_dim=feature_count, output_dim=embeddings_dimension, weights=[embedding_vectors], input_length=embeddings_sequence_length, trainable=trainable))\n","    model.add(GlobalAveragePooling1D())\n","    model.add(Dense(units=32, activation='relu', use_bias=True))\n","    model.add(Dense(units=32, activation='relu', use_bias=True))\n","    model.add(Dense(1, activation='sigmoid'))  # the value of 1 doesn't refer to the neuron count, e.g. for multi-class it refers to the number of categories\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.05),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":141,"outputs":[{"output_type":"stream","text":["Model: \"sequential_39\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_113 (Dense)            (None, 6)                 150       \n","_________________________________________________________________\n","dense_114 (Dense)            (None, 64)                448       \n","_________________________________________________________________\n","dense_115 (Dense)            (None, 3)                 195       \n","=================================================================\n","Total params: 793\n","Trainable params: 793\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0vyBBteypNGd","colab_type":"code","colab":{}},"source":["#SVG(keras.utils.vis_utils.model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))\n","# Hotfix\n","from keras.utils import plot_model\n","plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hovUZHJT4tAA","colab_type":"code","cellView":"both","outputId":"2379d693-2e7a-4bb4-a1d2-13d66d50a22f","colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"status":"ok","timestamp":1568768831021,"user_tz":-180,"elapsed":4065,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["### Parameters ###\n","batch_size = 32 #@param {type:\"integer\"}\n","epochs = 18 #@param {type:\"slider\", min:0, max:100, step:1}\n","###            ###\n","\n","history = model.fit(x=train_data,\n","                    y=train_labels,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2,\n","                    verbose=1)"],"execution_count":142,"outputs":[{"output_type":"stream","text":["Train on 188 samples, validate on 47 samples\n","Epoch 1/18\n","188/188 [==============================] - 2s 9ms/step - loss: 1.5395 - acc: 0.3457 - val_loss: 1.8765 - val_acc: 0.3191\n","Epoch 2/18\n","188/188 [==============================] - 0s 149us/step - loss: 1.2199 - acc: 0.4574 - val_loss: 1.0859 - val_acc: 0.4468\n","Epoch 3/18\n","188/188 [==============================] - 0s 141us/step - loss: 1.1419 - acc: 0.4149 - val_loss: 1.0831 - val_acc: 0.4681\n","Epoch 4/18\n","188/188 [==============================] - 0s 155us/step - loss: 1.0962 - acc: 0.4043 - val_loss: 1.0893 - val_acc: 0.3617\n","Epoch 5/18\n","188/188 [==============================] - 0s 161us/step - loss: 1.0418 - acc: 0.4202 - val_loss: 1.0297 - val_acc: 0.5106\n","Epoch 6/18\n","188/188 [==============================] - 0s 172us/step - loss: 1.0122 - acc: 0.4947 - val_loss: 1.0044 - val_acc: 0.5957\n","Epoch 7/18\n","188/188 [==============================] - 0s 155us/step - loss: 0.9834 - acc: 0.5532 - val_loss: 1.0789 - val_acc: 0.4894\n","Epoch 8/18\n","188/188 [==============================] - 0s 155us/step - loss: 0.9672 - acc: 0.5479 - val_loss: 1.0503 - val_acc: 0.3830\n","Epoch 9/18\n","188/188 [==============================] - 0s 153us/step - loss: 0.9786 - acc: 0.5372 - val_loss: 0.9614 - val_acc: 0.5106\n","Epoch 10/18\n","188/188 [==============================] - 0s 155us/step - loss: 0.9192 - acc: 0.6117 - val_loss: 0.9361 - val_acc: 0.5957\n","Epoch 11/18\n","188/188 [==============================] - 0s 154us/step - loss: 0.8667 - acc: 0.5691 - val_loss: 0.8856 - val_acc: 0.4894\n","Epoch 12/18\n","188/188 [==============================] - 0s 148us/step - loss: 0.8124 - acc: 0.6543 - val_loss: 0.8600 - val_acc: 0.6383\n","Epoch 13/18\n","188/188 [==============================] - 0s 161us/step - loss: 0.8070 - acc: 0.6915 - val_loss: 0.9569 - val_acc: 0.5106\n","Epoch 14/18\n","188/188 [==============================] - 0s 152us/step - loss: 0.7585 - acc: 0.7074 - val_loss: 0.9037 - val_acc: 0.5745\n","Epoch 15/18\n","188/188 [==============================] - 0s 142us/step - loss: 0.8204 - acc: 0.6330 - val_loss: 0.9143 - val_acc: 0.5957\n","Epoch 16/18\n","188/188 [==============================] - 0s 170us/step - loss: 0.7648 - acc: 0.6809 - val_loss: 1.2570 - val_acc: 0.4255\n","Epoch 17/18\n","188/188 [==============================] - 0s 147us/step - loss: 0.8526 - acc: 0.6117 - val_loss: 0.9217 - val_acc: 0.5319\n","Epoch 18/18\n","188/188 [==============================] - 0s 137us/step - loss: 0.7413 - acc: 0.6968 - val_loss: 1.0382 - val_acc: 0.5957\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8iY8AAAAOLMm","colab_type":"code","outputId":"8df7b70b-d468-4d1a-ad4a-82a446267584","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1568768831022,"user_tz":-180,"elapsed":1935,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["results = model.evaluate(test_data, test_labels)\n","print()\n","\n","for i in range(len(model.metrics_names)):\n","    if model.metrics_names[i] == \"acc\":\n","        print(f\"Final Metric - {model.metrics_names[i]}: {results[i]*100:.3f}\")\n","    else:\n","        print(f\"Final Metric - {model.metrics_names[i]}: {results[i]}\")  "],"execution_count":143,"outputs":[{"output_type":"stream","text":["59/59 [==============================] - 0s 145us/step\n","\n","Final Metric - loss: 0.942825636621249\n","Final Metric - acc: 59.322\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tAGmRQq3ukdo","colab_type":"text"},"source":["## Model Analysis"]},{"cell_type":"markdown","metadata":{"id":"U0A5sddZXEJ4","colab_type":"text"},"source":["### Model Analysis: Out-of-Vocabulary (OOV) words in Embeddings\n","\n","Obviously, assigning all OOV words the same \"UNK\" vector will decrease performance [[1](https://stackoverflow.com/questions/45495190/initializing-out-of-vocabulary-oov-tokens)].\n","\n","Other ideas:\n","- Simply remove all OOV words; too high time complexity.\n","- Assign the average of its surrounding words [[2](https://stackoverflow.com/questions/41517969/how-to-get-random-word2vec-vector-for-unknow-word)], but that would require running through the entire dataset and performing calculations, thus too high time complexity.\n","- Assign a unique random vector (uniform -0.5 to 0.5) to each word  [[1](https://stackoverflow.com/questions/45495190/initializing-out-of-vocabulary-oov-tokens)].\n","\n","| Approach (Using LSTM, 10 epochs) | Trainable On/Off | Performance |\n","| - | - | - | \n","| Pretrained, All OOV words set to a vector of zeros | False | 85.420 |\n","| Pretrained, All OOV words set to a vector of zeros | True | 87.500 |\n","| Pretrained, Each OOV word set to a unique random vector | False | 84.608 |\n","| Pretrained, Each OOV word set to a unique random vector | True | 87.568 |\n","| My own custom Word2Vec and use random vectors for OOV | False | 86.004 |\n","| My own custom Word2Vec and use random vectors for OOV | True | 87.612 |"]},{"cell_type":"markdown","metadata":{"id":"alnczQ9if68e","colab_type":"text"},"source":["### Model Analysis: **Overfitting**"]},{"cell_type":"code","metadata":{"id":"RX9OsCQKVd61","colab_type":"code","outputId":"efa102d7-530b-4dcf-daf5-6a16e41407a4","colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["def plot_model_history():\n","    plt.clf()  # clear figure\n","\n","    plt.style.use('ggplot')\n","\n","    acc = history.history['acc']\n","    val_acc = history.history['val_acc']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(acc) + 1)\n","\n","    plt.figure(figsize=(14, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, acc, 'b', label='Training acc')\n","    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.legend()\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, loss, 'bo', label='Training loss')\n","    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.legend()\n","    plt.show()\n","    \n","plot_model_history()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAzUAAAEJCAYAAACtywkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpK1/w+uz5jMDKGNUQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 1008x288 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"wTyPYITNYDw0","colab_type":"text"},"source":["After a certain number of Epochs the line continues to improve for the training data but does not for the validation data. This is a result of **overfiting**. After that point, the model over-optimizes and learns representations specific to the training data.\n","\n","We should simply stop training after a certain epoch. To prevent overfitting, the best solution is to use more training data or reduce the number of parameters (capacity). A model trained on more data will naturally generalize better. When that is no longer possible, the next best solution is to use techniques like regularization - two common such techniques are weight regularization and dropout. Concluding, the most common way to prevent overfitting are:\n","- Get more training data.\n","- Reduce the capacity of the network.\n","- Add weight regularization.\n","- Add dropout."]},{"cell_type":"markdown","metadata":{"id":"beQ4rpC0codS","colab_type":"text"},"source":["## Comparative Analysis of Parameters"]},{"cell_type":"markdown","metadata":{"id":"cy74T7xPgvou","colab_type":"text"},"source":["### **Model** Parameters \n","\n","Use GridSearchCV to automatically try all possible parameters combinations. Remember that we can't use the test set since it is considered cheating (data leak).\n","\n","| Parameter | Values | Best Performing |\n","| - | - | - |\n","| Batch Size | batch_size = [32, 64, 128, 256, 512, 1024] | (useless benchmark) curve with 128 being the peak, high deviation, big drop off at large values |\n","| Epochs | epochs = [1, 2, 3, 5, 10] | (useless benchmark) curve with 3 being the peak |\n","| Validation Set Split | validation_split = [0.0, 0.1, 0.25, 0.5] | the lower the better, 0.1 performs best |\n","| Neurons | neurons = [8, 16, 32, 64] | the higher the better |\n","| Embeddings Initializer | init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'] | 'uniform' 'normal' 'glorot_normal' 'he_normal' 'he_uniform' |\n","| Activation Function | activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] | 'linear' 'relu' 'tanh' 'softsign'|\n","| Optimizer | optimizer = ['Adam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'] | 'Adam' 'Adagrad' 'Adamax' |\n","\n","Some General Information [[1](https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/)]:\n","\n","| Problem type | Last-layer activation | Loss function | Example |\n","| - | - | - | - |\n","| Binary classification | sigmoid | binary_crossentropy | Dog vs. cat, Sentiment analysis |\n","| Multi-class, single-label classification | softmax | categorical_crossentropy | MNIST |\n","| Multi-class, multi-label classification | sigmoid | binary_crossentropy | News tags classification, one blog can have multiple tags |\n","| Regression to arbitrary values | None | mse | Predict house price (an integer/float) |\n","| Regression to values between 0 and 1 | sigmoid | mse or binary_crossentropy | Engine health assessment where 0 is broken, 1 is new |"]},{"cell_type":"code","metadata":{"id":"GLK_rNemh0wb","colab_type":"code","cellView":"both","colab":{}},"source":["### Parameters ###\n","run_this_section = False #@param {type:\"boolean\"}\n","###            ###\n","\n","if run_this_section == True:\n","    from keras.wrappers.scikit_learn import KerasClassifier\n","    from sklearn.model_selection import GridSearchCV\n","\n","    def create_model(neurons=16, init_mode='uniform', activation='relu', optimizer='Adam'):\n","        model = keras.Sequential()\n","        model.add(Embedding(input_dim=feature_count, output_dim=16, input_length=embeddings_sequence_length))  \n","        model.add(CuDNNLSTM(units=neurons))  # CuDNNLSTM: Tensorflow's default LSTM is awful at utilizing GPU/parallelization, [1] https://stackoverflow.com/a/47610747, [2] https://news.ycombinator.com/item?id=14538086\n","        model.add(Dropout(0.1, seed=random_state))\n","        model.add(Dense(units=neurons, activation=activation, use_bias=True))\n","        model.add(Dense(1, activation='sigmoid'))  # the value of 1 doesn't refer to the neuron count, e.g. for multi-class it refers to the number of categories\n","\n","        model.compile(optimizer='adam',\n","                      #optimizer=keras.optimizers.Adam(lr=optimizer),\n","                      loss='binary_crossentropy',\n","                      metrics=['accuracy'])   \n","\n","        return model\n","\n","    param_grid = dict(batch_size = [128],\n","                      epochs = [10],\n","                      validation_split = [0.0],\n","                      #neurons = [8, 16, 32, 64],\n","                      #init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n","                      #activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n","                      #kernel_constraint = [1, 2, 3, 4, 5],\n","                      #optimizer = ['Adam', 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam'],\n","                      #optimizer = [0.01, 0.001, 0.0005]\n","                     )\n","\n","    # Make use of Keras' scikit-learn API, also supports the parameters of the 'fit', 'predict', 'predict_proba', and 'score' methods\n","    model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=4, verbose=1, n_jobs=-1)  # Where 'cv' is the number of cross-validation folds\n","\n","    grid_result = grid.fit(train_data, train_labels)\n","\n","    print(f\"\\n- - - - - BEST PARAMETERS - - - - -\")\n","    print(f\"{grid_result.best_score_:.8f} using {grid_result.best_params_}\")\n","\n","    print(f\"\\n- - - - - DETAILS - - - - -\")\n","    for i in range(len(grid_result.cv_results_['params'])):         \n","        print(f\"mean - {grid_result.cv_results_['mean_test_score'][i]:.10f}; std - {grid_result.cv_results_['std_test_score'][i]:.10f} - {grid_result.cv_results_['params'][i]}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-zfSDox4_U8","colab_type":"text"},"source":["### Preprocessing Parameters\n","\n","Manually change the parameter at hand and note down the resulting accuracy. \n","Remember that we can't use the test set since it is considered cheating (data leak). However, the parameters tested here are of very general scope so we will use the test set anyway.\n","\n","```\n","elif embeddings_mode == \"One-hot Encoding\":\n","    model = keras.Sequential()\n","    model.add(Embedding(input_dim=feature_count, output_dim=16, input_length=embeddings_sequence_length))  \n","    model.add(CuDNNLSTM(units=neurons))\n","    model.add(Dropout(0.1, seed=random_state)) \n","    ...\n","    \n","validaiton_split = 0.1\n","```\n","\n","| Parameter| Values_1 | Value_2 | Value_3 | Value_4 | Note |\n","| - | - | - | - | - | - |\n","| Feature Count | 5000 | 10000 | 20000 | 30000 | - |\n","| _performance | 86.456 | 87.048 | 86.868 | 86.504 | - |\n","| Embeddings Sequence Length | 64 | 128 | 256 | 512 | doesn't have to be powers of 2 |\n","| _performance | 81.88 | 85.28 | 87.388 | 85.896 | - |\n","| Feature Count | - | 10000 | 20000 | 30000 | the first experiment but this time with much bigger sequence length |\n","| _performance | - | 86.708 | 87.004 | 86.812 | - |\n","| Remove First | True | False | - | - | - |\n","| _performance | 0.8664 | 0.86912  | - | - | - |"]},{"cell_type":"markdown","metadata":{"id":"lbJo7jLmrZ5h","colab_type":"text"},"source":["## Comparative Analysis of different Neural Networks\n","\n","My Parameters for IMDb Dataset (average length of instance is 238, max is 2494): random_state=22, feature_count=20000, remove_first=False, embeddings_mode=Word2Vec Pretrained, embeddings_sequence_length=256, Each OOV word set to a unique random vector, trainable=True, batch_size=256, epochs=EarlyStopping, activation=sigmoid, optimizer='adam', learning_rate=0.00005, validation_split=0.0, neurons=128.\n","\n","_ My Parameters For Subjectivity Dataset (average length of instance is 21.5, max is 111): Obviously we want a significantly shorter sequence length, a bit smaller batch size and a higher learning rate since the nature of the dataset is very different the the IMDb one. embeddings_sequence_length=32, batch_size=128, learning_rate=0.0001.\n","\n","_ My Parameters For Polarity Dataset (average length of instance is 18.8, max is 51): Obviously we want a significantly shorter sequence length, a bit smaller batch size and a higher learning rate since the nature of the dataset is very different the the IMDb one. embeddings_sequence_length=32, batch_size=128, learning_rate=0.00005.\n","\n","It is worth noting that the results are kind of random/useless because of the small size of the dataset as well as the fast convergence.\n","\n","| Model | Author | Performance (loss /acc) | Epochs | Embeddings Dimension | Note |\n","| - | - | - | - | - | - |\n","| Single LSTM | Me | 0.341 / 86.052 | 11 | 100 | This is run with One-hot Encoding - It reaches convergence too fast for Dropout or Deep to matter |\n","| Single LSTM with Dropout | Me | 0.339 / 86.556 | 8 | 100 | This is run with One-hot Encoding |\n","| Deep Stacked LSTMs with Dropout | Me | 0.346 / 85.188 | 4 | 100 | This is run with One-hot Encoding |\n","| Multilayer Perceptron | Me | 0.294 / 87.708 | 17 | 300 | Now we move to Word2Vec Pretrained |\n","| Multilayer Perceptron with Average Pooling | Me | 0.287 / 88.404 | 29 | 300 | - |\n","| Single LSTM | Me | 0.303 / 87.240 | 9 | 300 | - |\n","| Single LSTM with Dropout | Me | 0.307 / 87.048 | 12 | 300 | - |\n","| Bidirectional LSTM | Me | 0.297 / 87.456 | 10 | 300 | - |\n","| Bidirectional LSTM with Dropout | Me | 0.312 / 86.828 | 9 | 300 | - |\n","| Deep Stacked LSTMs  | Me | 0.326 / 86.396 | 8 | 300 | - |\n","| Deep Stacked LSTMs with Dropout | Me | 0.327 / 86.938 | 11 | 300 | - |\n","| Simple RNN | Me | 0.342 / 85.844 | 12 | 300 | - |\n","| Bidirectional Simple RNN | Me | 0.344 / 85.640 | 14 | 300 | - |\n","| GRU | Me | 0.298 / 87.776 | 7 | 300 | - |\n","| GRU with Dropout | Me | 0.298 / 87.572 | 11 | 300 | - |\n","| CNN with Average Pooling | Me | 0.286 / 88.424 | 4 | 300 | lr=0.0005 |\n","| LSTM inspired from Paper | [Liu et al.](https://aclweb.org/anthology/D15-1280) | 0.281 / 88.544 | 1 | 300 | We use the exact parameters from the paper with batch_size=128 and lr=0.05. Paper's accuracy: 88.50 |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 0.356 / 87.84 | 4 | 300 | (Useless since we lack processing power)) We use similar parameters to those from the paper but no dropout, units=128, batch_size=512. [Code](https://github.com/titu1994/Keras-Multiplicative-LSTM). Paper's accuracy: - |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 0.320 / 85.95 | 4 | 300 | (Useless since we lack processing power) We don't perform all the extra things the paper does, units=1000, batch_size=512. Paper's accuracy: - |\n","\n","| Model (on just 1 fold of cross_val) | Author | Performance | Epochs | Embeddings Dimension | Note |\n","| - | - | - | - | - | - |\n","| Single LSTM | Me | 90.400 | 7 | 100 | This is run with One-hot Encoding - It reaches convergence too fast for Dropout or Deep to matter |\n","| Single LSTM with Dropout | Me | 90.400 | 9 | 100 | This is run with One-hot Encoding |\n","| Deep Stacked LSTMs with Dropout | Me | 89.500 | 6 | 100 | This is run with One-hot Encoding |\n","| Multilayer Perceptron | Me | 91.400 | 8 | 300 | Now we move to Word2Vec Pretrained |\n","| Multilayer Perceptron with Average Pooling | Me | 92.300 | 10 | 300 | - |\n","| Single LSTM | Me | 90.400 | 6 | 300 | - |\n","| Single LSTM with Dropout | Me | 90.900 | 6 | 300 | - |\n","| Bidirectional LSTM | Me | 90.500 | 5 | 300 | - |\n","| Bidirectional LSTM with Dropout | Me | 90.200 | 5 | 300 | - |\n","| Deep Stacked LSTMs  | Me | 90.400 | 4 | 300 | - |\n","| Deep Stacked LSTMs with Dropout | Me | 90.700 | 6 | 300 | - |\n","| Simple RNN | Me | 89.200 | 7 | 300 | - |\n","| Bidirectional Simple RNN | Me | 90.300 | 7 | 300 | - |\n","| GRU | Me | 90.800 | 7 | 300 | - |\n","| GRU with Dropout | Me | 91.200 | 7 | 300 | - |\n","| CNN with Average Pooling | Me | 91.700 | 14 | 300 | lr=0.0005 |\n","| LSTM inspired from Paper | [Liu et al.](https://aclweb.org/anthology/D15-1280) | 91.100 | 1 | 300 | We use the exact parameters from the paper with units=60, batch_size=128 and lr=0.05. Paper's accuracy: - |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 91.900 | 3 | 300 | (Useless since we lack processing power)) We use similar parameters to those from the paper but no dropout, units=128, batch_size=512. [Code](https://github.com/titu1994/Keras-Multiplicative-LSTM). Paper's accuracy: - |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 90.000 | 4 | 300 | (Useless since we lack processing power) We don't perform all the extra things the paper does, units=1000, batch_size=128. Paper's accuracy: - |\n","\n","| Model (on just 1 fold of cross_val) | Author | Performance | Epochs | Embeddings Dimension | Note |\n","| - | - | - | - | - | - |\n","| Single LSTM | Me | 72.352 | 8 | 100 | This is run with One-hot Encoding - It reaches convergence too fast for Dropout or Deep to matter |\n","| Single LSTM with Dropout | Me | 72.638 | 10 | 100 | This is run with One-hot Encoding |\n","| Deep Stacked LSTMs with Dropout | Me | 71.516 | 7 | 100 | This is run with One-hot Encoding |\n","| Multilayer Perceptron | Me | 77.226 | 14 | 300 | Now we move to Word2Vec Pretrained |\n","| Multilayer Perceptron with Average Pooling | Me | 78.257 | 13 | 300 | - |\n","| Single LSTM | Me | 77.130 | 8 | 300 | - |\n","| Single LSTM with Dropout | Me | 75.351 | 6 | 300 | - |\n","| Bidirectional LSTM | Me | 78.913 | 5 | 300 | - |\n","| Bidirectional LSTM with Dropout | Me | 76.859 | 7 | 300 | - |\n","| Deep Stacked LSTMs  | Me | 72.541 | 1 | 300 | - |\n","| Deep Stacked LSTMs with Dropout | Me | 72.259 | 4 | 300 | - |\n","| Simple RNN | Me | 75.914 | 11 | 300 | - |\n","| Bidirectional Simple RNN | Me | 73.482 | 8 | 300 | - |\n","| GRU | Me | 78.163 | 8 | 300 | - |\n","| GRU with Dropout | Me | 78.738 | 12 | 300 | - |\n","| CNN with Average Pooling | Me | 79.007 | 17 | 300 | lr=0.0005 |\n","| LSTM inspired from Paper | [Liu et al.](https://aclweb.org/anthology/D15-1280) | 79.663 | 2 | 300 | We use the exact parameters from the paper with units=60, batch_size=128 and lr=0.005. Paper's accuracy: - |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 80.506 | 2 | 300 | (Useless since we lack processing power)) We use similar parameters to those from the paper but no dropout, units=128, batch_size=512. [Code](https://github.com/titu1994/Keras-Multiplicative-LSTM). Paper's accuracy: - |\n","| mLSTM inspired from Paper | [Krause et al.](https://arxiv.org/pdf/1609.07959.pdf) | 78.164 | 7 | 300 | (Useless since we lack processing power) We don't perform all the extra things the paper does, units=1000, batch_size=128. Paper's accuracy: - |"]},{"cell_type":"code","metadata":{"id":"CEERonQcDfYS","colab_type":"code","outputId":"f4d66516-3feb-4b33-8fdd-f430a806255e","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Adam print the weights when using  decay\n","if True:\n","    for i in range(5):\n","        beta_1 = 0.9 \n","        beta_2 = 0.999\n","        lr = 0.001\n","        decay = 0.01\n","\n","        lr = lr * (1. / (1. + decay * i))\n","        t = i + 1\n","        lr_t = lr * math.sqrt(1. - math.pow(beta_2, t)) / (1. - math.pow(beta_1, t))\n","        print(f\"Adam LR on epoch {i+1}: {lr_t:.6f}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Adam LR on epoch 1: 0.000316\n","Adam LR on epoch 2: 0.000233\n","Adam LR on epoch 3: 0.000198\n","Adam LR on epoch 4: 0.000178\n","Adam LR on epoch 5: 0.000166\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ABwHfx9ij2hy","colab_type":"code","outputId":"096dce5a-b86e-4e82-d513-d638adbf865c","colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["model = Sequential()\n","model.add(Embedding(input_dim=feature_count, output_dim=100, input_length=embeddings_sequence_length))  \n","#model.add(Embedding(input_dim=feature_count, output_dim=embeddings_dimension, weights=[embedding_vectors], input_length=embeddings_sequence_length, trainable=trainable))\n","#model.add(Dropout(0.2, seed=random_state))  # Maybe remove the seed since it makes it biased\n","#model.add(Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1))\n","#model.add(GlobalAveragePooling1D())\n","#model.add(keras.layers.Flatten())\n","model.add(CuDNNLSTM(units=128, return_sequences=True))\n","model.add(CuDNNLSTM(units=128, return_sequences=True))\n","#model.add(MultiplicativeLSTM(units=128))\n","model.add(CuDNNLSTM(units=128))\n","#model.add(keras.layers.Flatten())\n","#model.add(keras.layers.BatchNormalization())\n","#model.add(CuDNNLSTM(units=60, kernel_regularizer=keras.regularizers.l2(0.00001)))  # CuDNNLSTM: Tensorflow's default LSTM is awful at utilizing GPU/parallelization, [1] https://stackoverflow.com/a/47610747, [2] https://news.ycombinator.com/item?id=14538086\n","model.add(Dropout(0.5, seed=random_state))  \n","#model.add(Dense(units=128, activation='relu', use_bias=True))\n","#model.add(Dense(units=128, activation='relu', use_bias=True))\n","#model.add(keras.layers.Flatten())\n","model.add(Dense(1, activation='sigmoid'))  # the value of 1 doesn't refer to the neuron count, e.g. for multi-class it refers to the number of categories\n","\n","model.summary()\n","\n","model.compile(#optimizer=Adagrad(lr=0.005),\n","              optimizer=Adam(lr=0.00005),  # or 0.0005 or even better 0.00005\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', mode='min', baseline=0.70, patience=3, verbose=1)\n","model_save = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_12 (Embedding)     (None, 26, 100)           1857500   \n","_________________________________________________________________\n","cu_dnnlstm_12 (CuDNNLSTM)    (None, 26, 128)           117760    \n","_________________________________________________________________\n","cu_dnnlstm_13 (CuDNNLSTM)    (None, 26, 128)           132096    \n","_________________________________________________________________\n","cu_dnnlstm_14 (CuDNNLSTM)    (None, 128)               132096    \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1)                 129       \n","=================================================================\n","Total params: 2,239,581\n","Trainable params: 2,239,581\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1N4bJDWmj7z_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":857},"outputId":"149e3fc4-6b56-4daa-f890-2fa6860564ff","executionInfo":{"status":"ok","timestamp":1568766255516,"user_tz":-180,"elapsed":678,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}}},"source":["SVG(keras.utils.vis_utils.model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg height=\"627pt\" viewBox=\"0.00 0.00 512.00 470.00\" width=\"683pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 466)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-466 508,-466 508,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139867347479520 -->\n<g class=\"node\" id=\"node1\">\n<title>139867347479520</title>\n<polygon fill=\"none\" points=\"80.5,-415.5 80.5,-461.5 423.5,-461.5 423.5,-415.5 80.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-434.8\">embedding_3_input: InputLayer</text>\n<polyline fill=\"none\" points=\"285.5,-415.5 285.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"285.5,-438.5 343.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"343.5,-415.5 343.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.5\" y=\"-446.3\">(None, 24)</text>\n<polyline fill=\"none\" points=\"343.5,-438.5 423.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.5\" y=\"-423.3\">(None, 24)</text>\n</g>\n<!-- 139867347479352 -->\n<g class=\"node\" id=\"node2\">\n<title>139867347479352</title>\n<polygon fill=\"none\" points=\"86.5,-332.5 86.5,-378.5 417.5,-378.5 417.5,-332.5 86.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-351.8\">embedding_3: Embedding</text>\n<polyline fill=\"none\" points=\"257.5,-332.5 257.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"257.5,-355.5 315.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"315.5,-332.5 315.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-363.3\">(None, 24)</text>\n<polyline fill=\"none\" points=\"315.5,-355.5 417.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-340.3\">(None, 24, 16)</text>\n</g>\n<!-- 139867347479520&#45;&gt;139867347479352 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139867347479520-&gt;139867347479352</title>\n<path d=\"M252,-415.3799C252,-407.1745 252,-397.7679 252,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.5001,-388.784 252,-378.784 248.5001,-388.784 255.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867350762888 -->\n<g class=\"node\" id=\"node3\">\n<title>139867350762888</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 504,-295.5 504,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-268.8\">global_average_pooling1d_3: GlobalAveragePooling1D</text>\n<polyline fill=\"none\" points=\"344,-249.5 344,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"344,-272.5 402,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"402,-249.5 402,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-280.3\">(None, 24, 16)</text>\n<polyline fill=\"none\" points=\"402,-272.5 504,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-257.3\">(None, 16)</text>\n</g>\n<!-- 139867347479352&#45;&gt;139867350762888 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139867347479352-&gt;139867350762888</title>\n<path d=\"M252,-332.3799C252,-324.1745 252,-314.7679 252,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.5001,-305.784 252,-295.784 248.5001,-305.784 255.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867350763336 -->\n<g class=\"node\" id=\"node4\">\n<title>139867350763336</title>\n<polygon fill=\"none\" points=\"126,-166.5 126,-212.5 378,-212.5 378,-166.5 126,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-185.8\">dense_25: Dense</text>\n<polyline fill=\"none\" points=\"240,-166.5 240,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"240,-189.5 298,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-166.5 298,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-197.3\">(None, 16)</text>\n<polyline fill=\"none\" points=\"298,-189.5 378,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-174.3\">(None, 16)</text>\n</g>\n<!-- 139867350762888&#45;&gt;139867350763336 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139867350762888-&gt;139867350763336</title>\n<path d=\"M252,-249.3799C252,-241.1745 252,-231.7679 252,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.5001,-222.784 252,-212.784 248.5001,-222.784 255.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867346578232 -->\n<g class=\"node\" id=\"node5\">\n<title>139867346578232</title>\n<polygon fill=\"none\" points=\"126,-83.5 126,-129.5 378,-129.5 378,-83.5 126,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-102.8\">dense_26: Dense</text>\n<polyline fill=\"none\" points=\"240,-83.5 240,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"240,-106.5 298,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-83.5 298,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-114.3\">(None, 16)</text>\n<polyline fill=\"none\" points=\"298,-106.5 378,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-91.3\">(None, 16)</text>\n</g>\n<!-- 139867350763336&#45;&gt;139867346578232 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139867350763336-&gt;139867346578232</title>\n<path d=\"M252,-166.3799C252,-158.1745 252,-148.7679 252,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.5001,-139.784 252,-129.784 248.5001,-139.784 255.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139867346652520 -->\n<g class=\"node\" id=\"node6\">\n<title>139867346652520</title>\n<polygon fill=\"none\" points=\"126,-.5 126,-46.5 378,-46.5 378,-.5 126,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-19.8\">dense_27: Dense</text>\n<polyline fill=\"none\" points=\"240,-.5 240,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"240,-23.5 298,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"298,-.5 298,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-31.3\">(None, 16)</text>\n<polyline fill=\"none\" points=\"298,-23.5 378,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139867346578232&#45;&gt;139867346652520 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139867346578232-&gt;139867346652520</title>\n<path d=\"M252,-83.3799C252,-75.1745 252,-65.7679 252,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"255.5001,-56.784 252,-46.784 248.5001,-56.784 255.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"NZUXZS5IkBOj","colab_type":"code","outputId":"f29b4787-6588-41b1-805b-4b31fd8e396d","colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["history = model.fit(x=train_data,\n","                    y=train_labels,\n","                    batch_size=128,\n","                    epochs=40,\n","                    validation_data=(test_data, test_labels),  \n","                    # The above really isn't \"cheating\", it's the equivalent of trying different parameters manually till we find the best for the specific model we are building like \n","                    # research papers do. Obviously, here we train different models on different number of epochs instead of comparing a set of models on the same number of epochs N\n","                    #validation_split=0.1,\n","                    callbacks=[early_stop, model_save],\n","                    verbose=1)\n","\n","model = load_model('best_model.h5')\n","#model = load_model('best_model.h5', custom_objects={'MultiplicativeLSTM': MultiplicativeLSTM})  # Handling saved models changes if we are using custom (3rd-party) layers\n","\n","results = model.evaluate(test_data, test_labels)\n","print()\n","\n","for i in range(len(model.metrics_names)):\n","    if model.metrics_names[i] == \"acc\":\n","        print(f\"Final Metric of the best val_loss model - {model.metrics_names[i]}: {results[i]*100:.3f}\")\n","    else:\n","        print(f\"Final Metric of the best val_loss model - {model.metrics_names[i]}: {results[i]}\")       "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 9595 samples, validate on 1067 samples\n","Epoch 1/40\n","9595/9595 [==============================] - 6s 623us/step - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6928 - val_acc: 0.5604\n","Epoch 2/40\n","9595/9595 [==============================] - 2s 228us/step - loss: 0.6926 - acc: 0.5551 - val_loss: 0.6921 - val_acc: 0.5914\n","Epoch 3/40\n","9595/9595 [==============================] - 2s 205us/step - loss: 0.6885 - acc: 0.5577 - val_loss: 0.6783 - val_acc: 0.5979\n","Epoch 4/40\n","9595/9595 [==============================] - 2s 203us/step - loss: 0.6281 - acc: 0.6542 - val_loss: 0.6333 - val_acc: 0.6523\n","Epoch 5/40\n","9595/9595 [==============================] - 2s 205us/step - loss: 0.5287 - acc: 0.7414 - val_loss: 0.6085 - val_acc: 0.6954\n","Epoch 6/40\n","9595/9595 [==============================] - 2s 203us/step - loss: 0.4331 - acc: 0.8046 - val_loss: 0.6427 - val_acc: 0.6720\n","Epoch 7/40\n","9595/9595 [==============================] - 2s 200us/step - loss: 0.3549 - acc: 0.8435 - val_loss: 0.6667 - val_acc: 0.6823\n","Epoch 8/40\n","9595/9595 [==============================] - 2s 203us/step - loss: 0.2936 - acc: 0.8786 - val_loss: 0.7235 - val_acc: 0.6870\n","Epoch 9/40\n","9595/9595 [==============================] - 2s 200us/step - loss: 0.2517 - acc: 0.8950 - val_loss: 0.7644 - val_acc: 0.7010\n","Epoch 10/40\n","9595/9595 [==============================] - 2s 208us/step - loss: 0.2179 - acc: 0.9087 - val_loss: 0.7922 - val_acc: 0.7076\n","Epoch 11/40\n","9595/9595 [==============================] - 2s 209us/step - loss: 0.1835 - acc: 0.9274 - val_loss: 0.9467 - val_acc: 0.6982\n","Epoch 12/40\n","9595/9595 [==============================] - 2s 203us/step - loss: 0.1577 - acc: 0.9372 - val_loss: 0.9968 - val_acc: 0.6954\n","Epoch 00012: early stopping\n","1067/1067 [==============================] - 2s 1ms/step\n","\n","Final Metric of the best val_loss model - loss: 0.6085010721734895\n","Final Metric of the best val_loss model - acc: 69.541\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LFCtgXrIkP7s","colab_type":"text"},"source":["## Other Ideas\n","\n","keras.preprocessing.sequence.skipgrams  (can also be done via Word2Vec in gensim)"]}]}