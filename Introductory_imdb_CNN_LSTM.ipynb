{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpython36gpucondaddc583380ab244559338bc9665ae388d",
   "display_name": "Python 3.6.9 64-bit ('python36gpu': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    },
    {
     "data": {
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/unreal/Introductory_imdb_CNN_LSTM\" target=\"_blank\">https://app.wandb.ai/unreal/Introductory_imdb_CNN_LSTM</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/unreal/Introductory_imdb_CNN_LSTM/runs/vrub2et8\" target=\"_blank\">https://app.wandb.ai/unreal/Introductory_imdb_CNN_LSTM/runs/vrub2et8</a><br/>\n            ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "The classic and simple LSTM on keras example, from the official repository.\n",
    "~~Train a recurrent convolutional network on the IMDB sentiment classification task.~~\n",
    "~~Baseline: gets to 0.8498 test accuracy after 2 epochs. 41 s/epoch on K520 GPU.~~\n",
    "~~batch_size is highly sensitive.~~\n",
    "~~Only 2 epochs are needed as the dataset is very small.~~\n",
    "'''\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## PARAMETERS ##\n",
    "print_tensorflow_GPU_info = False\n",
    "wandb.init(entity='unreal', project='Introductory_imdb_CNN_LSTM', name=None, notes=None, anonymous=None)\n",
    "config = wandb.config  # config is a variable that holds and saves hyperparameters and inputs\n",
    "config.random_state = 22\n",
    "config.tensorflow_verbosity = \"INFO\"  # DEBUG(10): All | INFO(20): Info&Warning | WARN(30)[Default]: Warning | ERROR(40): Error | FATAL(50): None\n",
    "    # Embedding\n",
    "config.max_features = 20000\n",
    "config.maxlen = 100\n",
    "config.embedding_size = 128\n",
    "config.dropout = 0.25\n",
    "    # Convolution\n",
    "config.kernel_size = 5\n",
    "config.filters = 64\n",
    "config.pool_size = 4\n",
    "    # LSTM\n",
    "config.lstm_output_size = 70\n",
    "    # Training\n",
    "config.batch_size = 30\n",
    "config.epochs = 2\n",
    "config.loss=\"binary_crossentropy\"\n",
    "config.optimizer=\"adam\"\n",
    "config.eval_metrics=\"accuracy\"\n",
    "##             ##\n",
    "\n",
    "## Reproducibility ## \n",
    "random.seed(config.random_state)  # Python's seed\n",
    "np.random.seed(config.random_state)  # Numpy's seed\n",
    "tf.set_random_seed(config.random_state)  # Tensorflow's seed\n",
    "##                 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n--CHANGED TENSORFLOW VERBOSITY FROM 2 (default) TO 2\n"
    }
   ],
   "source": [
    "## RTX GPU Memory BUG Fix & Must also be placed at the top of the code else it doesn't work ##\n",
    "from keras.backend import tensorflow_backend as K\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True                     # dynamically grow the memory used on the GPU\n",
    "#tf_config.gpu_options.per_process_gpu_memory_fraction = 0.9  # fraction of the GPU to be used\n",
    "#tf_config.log_device_placement = True                        # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=tf_config)\n",
    "K.set_session(sess)                     # set this TensorFlow session as the default session for Keras\n",
    "##                                                                                          ##     \n",
    "\n",
    "## Tensorflow Verbosity Module ##\n",
    "default_verbosity = tf.compat.v1.logging.get_verbosity()\n",
    "tf.compat.v1.logging.set_verbosity(config.tensorflow_verbosity)\n",
    "print(f\"\\n--CHANGED TENSORFLOW VERBOSITY FROM {default_verbosity/10:.0f} (default) TO {tf.compat.v1.logging.get_verbosity()/10:.0f}\")\n",
    "##                             ##\n",
    "\n",
    "## Tensorflow GPU Information Module ##\n",
    "if print_tensorflow_GPU_info == True:\n",
    "    print(f\"\\n--AVAILABLE GPUS:\")\n",
    "    K._get_available_gpus()\n",
    "    print(f\"\\n--NUM OF GPUs AVAILABLE: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    "    print(f\"\\n--IS TF BUILT WITH CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "    print(f\"\\n--IS GPU AVAILABLE: {tf.test.is_gpu_available()}\")\n",
    "##                                   ##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nLoading data...\n25000 train sequences\n25000 test sequences\nPadding sequences (samples x time)\nx_train shape: (25000, 100)\nx_test shape: (25000, 100)\n"
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "print(f\"\\nLoading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=config.max_features)\n",
    "print(f\"{len(x_train)} train sequences\")\n",
    "print(f\"{len(x_test)} test sequences\")\n",
    "\n",
    "print(f\"Padding sequences (samples x time)\")\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=config.maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=config.maxlen)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nBuilding model...\nWARNING:tensorflow:From E:\\Anaconda3\\envs\\python36gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From E:\\Anaconda3\\envs\\python36gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From E:\\Anaconda3\\envs\\python36gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "# Model Building\n",
    "print(f\"\\nBuilding model...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(config.max_features, config.embedding_size, input_length=config.maxlen))\n",
    "model.add(Dropout(config.dropout))\n",
    "model.add(Conv1D(config.filters,\n",
    "                 config.kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=config.pool_size))\n",
    "model.add(LSTM(config.lstm_output_size))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=config.loss,\n",
    "              optimizer=config.optimizer,\n",
    "              metrics=[config.eval_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training...\nWARNING:tensorflow:From E:\\Anaconda3\\envs\\python36gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nTrain on 25000 samples, validate on 25000 samples\nEpoch 1/2\n25000/25000 [==============================] - 24s 944us/step - loss: 0.3900 - accuracy: 0.8140 - val_loss: 0.3209 - val_accuracy: 0.8585\nEpoch 2/2\n25000/25000 [==============================] - 22s 887us/step - loss: 0.1943 - accuracy: 0.9268 - val_loss: 0.3411 - val_accuracy: 0.8546\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x19bc2510898>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "print(f\"Training...\")\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=config.batch_size,\n",
    "          epochs=config.epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[WandbCallback(monitor=\"val_loss\", mode=\"auto\", save_weights_only=False, save_model=False)])  # can also operate similarly to ModelCheckpoint as well as a validator for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "25000/25000 [==============================] - 7s 297us/step\nTest loss: 34.10981\nTest accuracy: 85.46000\n"
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=config.batch_size)\n",
    "print(f\"Test loss: {score*100:.5f}\")\n",
    "print(f\"Test accuracy: {acc*100:.5f}\")"
   ]
  }
 ]
}