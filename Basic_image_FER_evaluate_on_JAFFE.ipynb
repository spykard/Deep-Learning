{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "###            ###\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "## PARAMETERS ##\n",
    "print_tensorflow_GPU_info = False\n",
    "tensorflow_verbosity = \"INFO\"  # DEBUG(10): All | INFO(20): Info&Warning | WARN(30)[Default]: Warning | ERROR(40): Error | FATAL(50): None\n",
    "random_state = 22\n",
    "    # General\n",
    "dataset_name = \"JAFFE\"\n",
    "multiclass = True\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "width, height = 197, 197\n",
    "channels = 3\n",
    "load_npy = True\n",
    "data_generator = False\n",
    "    # Convolution\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "strides = (2, 2)\n",
    "dropout = 0.3\n",
    "    # Training\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "loss = \"categorical_crossentropy\"\n",
    "optimizer = \"adam\"\n",
    "eval_metrics = \"accuracy\"\n",
    "##             ##\n",
    "\n",
    "## Reproducibility ## \n",
    "random.seed(random_state)  # Python's seed\n",
    "np.random.seed(random_state)  # Numpy's seed\n",
    "tf.set_random_seed(random_state)  # Tensorflow's seed\n",
    "##                 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--CHANGED TENSORFLOW VERBOSITY FROM 2 (default) TO 2\n"
     ]
    }
   ],
   "source": [
    "## GPU usage settings for Tensorflow backend ##\n",
    "# RTX GPU Memory BUG Fix & Must also be placed at the top of the code else it doesn't work\n",
    "from keras.backend import tensorflow_backend as K\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True                     # dynamically grow the memory used on the GPU\n",
    "#tf_config.gpu_options.per_process_gpu_memory_fraction = 0.9  # fraction of the GPU to be used\n",
    "#tf_config.log_device_placement = True                        # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=tf_config)\n",
    "K.set_session(sess)                     # set this TensorFlow session as the default session for Keras\n",
    "##                                                                                          ##     \n",
    "\n",
    "## Tensorflow Verbosity Module ##\n",
    "default_verbosity = tf.compat.v1.logging.get_verbosity()\n",
    "tf.compat.v1.logging.set_verbosity(tensorflow_verbosity)\n",
    "print(f\"\\n--CHANGED TENSORFLOW VERBOSITY FROM {default_verbosity/10:.0f} (default) TO {tf.compat.v1.logging.get_verbosity()/10:.0f}\")\n",
    "##                             ##\n",
    "\n",
    "## Tensorflow GPU Information Module ##\n",
    "if print_tensorflow_GPU_info == True:\n",
    "    print(f\"\\n--AVAILABLE GPUS:\")\n",
    "    K._get_available_gpus()\n",
    "    print(f\"\\n--NUM OF GPUs AVAILABLE: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    "    print(f\"\\n--IS TF BUILT WITH CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "    print(f\"\\n--IS GPU AVAILABLE: {tf.test.is_gpu_available()}\")\n",
    "##                                   ##  "
   ]
  },
  {
   "source": [
    "# Load JAFFE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded the images of dataset-ANGRY with length 30\n",
      "Loaded the images of dataset-DISGUST with length 29\n",
      "Loaded the images of dataset-FEAR with length 32\n",
      "Loaded the images of dataset-HAPPY with length 31\n",
      "Loaded the images of dataset-NEUTRAL with length 30\n",
      "Loaded the images of dataset-SAD with length 31\n",
      "Loaded the images of dataset-SURPRISE with length 30\n",
      "[[[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]\n",
      "\n",
      " [[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]\n",
      "\n",
      " [[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]\n",
      "\n",
      " [[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]\n",
      "\n",
      " [[-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  ...\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]\n",
      "  [-103.939 -116.779 -123.68 ]]]\n",
      "[[[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]\n",
      "\n",
      " [[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]\n",
      "\n",
      " [[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]\n",
      "\n",
      " [[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]\n",
      "\n",
      " [[-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  ...\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]\n",
      "  [-227.619 -233.558 -227.619]]]\n",
      "(213, 197, 197, 3) \n",
      "\n",
      "Loading Done\n"
     ]
    }
   ],
   "source": [
    "if dataset_name == \"JAFFE\":\n",
    "    # Load images\n",
    "    data_path = \"./Datasets/Japanese Female Facial Expression (JAFFE) Dataset/PNG Format\"    \n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    img_data_list=[]\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{} with length {}'.format(dataset, len(img_list)))\n",
    "        for img in img_list:\n",
    "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img, cv2.IMREAD_COLOR)  # Dataset is actually Grayscale\n",
    "            input_img=cv2.resize(input_img, (197,197))  # RESIZE Required\n",
    "            img_data_list.append(input_img)\n",
    "            \n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    #X = img_data/255\n",
    "\n",
    "    # Make image VGG compatible (3 channels instead of 1 channel gray scale, BGR, etc.)\n",
    "    X_new = np.empty((len(X), width, height, channels))\n",
    "    print(X[1])\n",
    "    for i in range(len(X)):\n",
    "        X_new[i] = preprocess_input(X[i], mode='caffe')\n",
    "    X = X_new\n",
    "    print(X_new[1])    \n",
    "    del X_new\n",
    "    del img_data\n",
    "\n",
    "    print(X.shape, \"\\n\")\n",
    "\n",
    "    # Define the number of classes\n",
    "    num_of_samples = X.shape[0]\n",
    "    labels = np.ones((num_of_samples,), dtype='int64')\n",
    "    labels[0:30]=0 #30\n",
    "    labels[30:59]=1 #29\n",
    "    labels[59:91]=2 #32\n",
    "    labels[91:122]=3 #31\n",
    "    labels[122:152]=4 #30\n",
    "    labels[152:183]=5 #31\n",
    "    labels[183:]=6 #30  \n",
    "\n",
    "    # Class Label Names    \n",
    "    label_names = ['ANGRY', 'DISGUST', 'FEAR', 'HAPPY', 'NEUTRAL', 'SAD', 'SURPRISE']\n",
    "\n",
    "    # Convert class labels to on-hot encoding \n",
    "    y = to_categorical(labels, num_labels)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    X, y = shuffle(X, y, random_state=random_state)\n",
    "    print(\"Loading Done\")\n",
    "\n",
    "elif dataset_name == \"SFEW\":\n",
    "    # Load images from Train Folder\n",
    "    data_path = \"./Datasets/Static Facial Expression In The Wild (SFEW) Dataset/SFEW_2/Train\"    \n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    img_data_list=[]\n",
    "    labels=[]\n",
    "    count = 0\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        if (dataset.endswith(\".zip\") != True):\n",
    "            img_list=os.listdir(data_path+'/'+ dataset)\n",
    "            print ('Loaded the images of dataset-'+'{} with length {}'.format(dataset, len(img_list)))\n",
    "            for img in img_list:\n",
    "                input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img, cv2.IMREAD_COLOR)  # Dataset is RGB\n",
    "                input_img = input_img[:, 72:648]  # CROP Required\n",
    "                input_img=cv2.resize(input_img, (48,48))  # RESIZE Required\n",
    "                img_data_list.append(input_img)\n",
    "                labels.append(count)\n",
    "            count += 1\n",
    "\n",
    "    # Also images from Val Folder\n",
    "    data_path = \"./Datasets/Static Facial Expression In The Wild (SFEW) Dataset/SFEW_2/Val\"    \n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        if (dataset.endswith(\".zip\") != True):\n",
    "            img_list=os.listdir(data_path+'/'+ dataset)\n",
    "            print ('Loaded the images of dataset-'+'{} with length {}'.format(dataset, len(img_list)))\n",
    "            for img in img_list:\n",
    "                input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img, cv2.IMREAD_COLOR)  # Dataset is RGB\n",
    "                input_img = input_img[:, 72:648]  # CROP Required\n",
    "                input_img=cv2.resize(input_img, (48,48))  # RESIZE Required\n",
    "                img_data_list.append(input_img)\n",
    "                labels.append(count)\n",
    "            count += 1\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    X = img_data/255\n",
    "\n",
    "    # Make image VGG compatible (3 channels instead of 1 channel gray scale, BGR, etc.)\n",
    "    X_new = np.empty((len(X), width, height, channels))\n",
    "    for i in range(len(X)):\n",
    "        X_new[i] = preprocess_input(X[i], mode='caffe')\n",
    "    X = X_new\n",
    "    del X_new\n",
    "    del img_data\n",
    "\n",
    "    print(X.shape, \"\\n\")\n",
    "    labels = np.asarray(labels, dtype='int64')\n",
    "\n",
    "    # Class Label Names    \n",
    "    label_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "    # Convert class labels to on-hot encoding \n",
    "    y = to_categorical(labels, num_labels)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    X, y = shuffle(X, y, random_state=random_state)\n",
    "    print(\"Loading Done\")\n",
    "    print(len(X))    "
   ]
  },
  {
   "source": [
    "# Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load Model '''\n",
    "model = load_model('Saved Models/GitHub-FER_ResNet50_VGGFace.h5')"
   ]
  },
  {
   "source": [
    "# Evaluate on JAFFE (need to also make sure that labels match the FER dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X\n",
    "y_test = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "213/213 [==============================] - 2s 8ms/step\n",
      "\n",
      "Metric - loss: 28916.83825\n",
      "Metric - accuracy: 14.08451\n",
      "\n",
      "[[ 0  0  0  0 30  0  0]\n",
      " [ 0  0  0  0 29  0  0]\n",
      " [ 0  0  0  0 32  0  0]\n",
      " [ 0  0  0  0 31  0  0]\n",
      " [ 0  0  0  0 30  0  0]\n",
      " [ 0  0  0  0 31  0  0]\n",
      " [ 0  0  0  0 30  0  0]]\n"
     ]
    }
   ],
   "source": [
    "''' Evaluate Model '''\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print()\n",
    "\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(\"Metric - {}: {:.5f}\".format(model.metrics_names[i], results[i]*100))\n",
    "\n",
    "if multiclass == False: \n",
    "    predictions = [1 * (x[0]>=0.5) for x in model.predict(X_test)]\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "else:    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "    cm = confusion_matrix(y_test.argmax(axis=1), predictions)\n",
    "print()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}