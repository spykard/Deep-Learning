{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_Learning_Intro.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["16DWjms_doQ6","1FWXTjf4cBBv","g03N8YTOmlb4","tD2sucV6dGl1","k5w5_4z8czaR","K_zRgGyseTEE","la_XtomXekfM"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"16DWjms_doQ6","colab_type":"text"},"cell_type":"markdown","source":["## GPU General Information"]},{"metadata":{"id":"Ge8W3GuTEZD0","colab_type":"code","outputId":"f5c179c4-cf4e-4e2f-fd96-0fb66b277186","executionInfo":{"status":"ok","timestamp":1556531385320,"user_tz":-180,"elapsed":4472,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":680}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","print(f\"--- {tf.test.is_gpu_available()}\\n\")\n","print(f\"--- {tf.test.gpu_device_name()}\\n\")\n","print(f\"--- {tf.test.is_built_with_cuda()}\\n\")\n","print(f\"---\\n{device_lib.list_local_devices()}\\n\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--- True\n","\n","--- /device:GPU:0\n","\n","--- True\n","\n","---\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 8579727292705048111\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 10537519461365303144\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 9696202087337450214\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14800692839\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 577378201317793296\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"z7bZQb-YjxmA","colab_type":"text"},"cell_type":"markdown","source":["Previous execution some weeks ago showed that a **Tesla K80** was used instead.\n","\n","```\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 10550069380342432296\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 16510589324407396482\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 12770818163539961133\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 11276884378\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 13215302358784350175\n","physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n","]\n","```\n","\n","Followed by a **Tesla T4**.\n","\n"," ```\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 13999904789832453405\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 2474607553434206280\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 5105918168026004920\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14800630580\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 8208043236747855715\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","] \n","```"]},{"metadata":{"id":"1FWXTjf4cBBv","colab_type":"text"},"cell_type":"markdown","source":["## GPU Memory Availability Testing\n","\n","Just to make sure that Google isn't purposely limiting access to the GPU memory."]},{"metadata":{"id":"EUwDbuBDVKNO","colab_type":"code","outputId":"3133b3a7-4036-4450-d7aa-478f67e354bd","executionInfo":{"status":"ok","timestamp":1556531967736,"user_tz":-180,"elapsed":12969,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["# Source: https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# Only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printX():\n","    process = psutil.Process(os.getpid())\n","    print(f\"Gen RAM Free: {humanize.naturalsize(psutil.virtual_memory().available)} | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n","    print(f\"GPU RAM Free: {gpu.memoryFree:.0f} MB | Used: {gpu.memoryUsed:.0f} MB | Util {gpu.memoryUtil*100:.0f}% | Total {gpu.memoryTotal:.0f} MB\")\n","printX()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.4 GB | Proc size: 904.7 MB\n","GPU RAM Free: 14858 MB | Used: 221 MB | Util 1% | Total 15079 MB\n"],"name":"stdout"}]},{"metadata":{"id":"g03N8YTOmlb4","colab_type":"text"},"cell_type":"markdown","source":["## CPU General Information\n","\n","The CPU appears to have two cores available."]},{"metadata":{"id":"M1cilSMMmjkA","colab_type":"code","outputId":"12d2e0f2-51e1-4778-a54c-677ff0a67d68","executionInfo":{"status":"ok","timestamp":1555998297169,"user_tz":-180,"elapsed":2098,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":474}},"cell_type":"code","source":["!lscpu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               79\n","Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Stepping:            0\n","CPU MHz:             2200.000\n","BogoMIPS:            4400.00\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            56320K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat arch_capabilities\n"],"name":"stdout"}]},{"metadata":{"id":"tD2sucV6dGl1","colab_type":"text"},"cell_type":"markdown","source":["## A basic Deep Learning Example #1\n","\n","A text classification task on the IMDb Dataset."]},{"metadata":{"id":"Ok_qXRgOQ2rH","colab_type":"code","outputId":"09c7c109-83b9-44fe-c5ea-57d8bcc3ac8d","executionInfo":{"status":"ok","timestamp":1555998333823,"user_tz":-180,"elapsed":12523,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":674}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import numpy as np\n","\n","imdb = keras.datasets.imdb\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n","\n","print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))\n","\n","word_index = imdb.get_word_index()\n","word_index[\"<PAD>\"] = 0\n","word_index[\"<START>\"] = 1\n","word_index[\"<UNK>\"] = 2  # unknown\n","word_index[\"<UNUSED>\"] = 3\n","\n","train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n","                                                        value=word_index[\"<PAD>\"],\n","                                                        padding='post',\n","                                                        maxlen=256)\n","\n","test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n","                                                       value=word_index[\"<PAD>\"],\n","                                                       padding='post',\n","                                                       maxlen=256)\n","\n","#print(train_data[0], type(train_data[0]))\n","\n","# input shape is the vocabulary count used for the movie reviews (10,000 words)\n","vocab_size = 10000\n","\n","model = keras.Sequential()\n","model.add(keras.layers.Embedding(vocab_size, 16))\n","#model.add(keras.layers.Bidirectional(tf.keras.layers.LSTM(16)))\n","model.add(keras.layers.GlobalAveragePooling1D())\n","model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n","model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n","\n","model.summary()\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","x_val = train_data[:10000]\n","partial_x_train = train_data[10000:]\n","\n","y_val = train_labels[:10000]\n","partial_y_train = train_labels[10000:]\n","\n","history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=4,\n","                    batch_size=128,\n","                    validation_data=(x_val, y_val),\n","                    verbose=1)\n","\n","results = model.evaluate(test_data, test_labels)\n","\n","print(results)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training entries: 25000, labels: 25000\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 16)          160000    \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 16)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 16)                272       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 17        \n","=================================================================\n","Total params: 160,289\n","Trainable params: 160,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 15000 samples, validate on 10000 samples\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/4\n","15000/15000 [==============================] - 1s 75us/sample - loss: 0.6875 - acc: 0.6577 - val_loss: 0.6739 - val_acc: 0.6917\n","Epoch 2/4\n","15000/15000 [==============================] - 1s 41us/sample - loss: 0.6307 - acc: 0.7678 - val_loss: 0.5769 - val_acc: 0.7989\n","Epoch 3/4\n","15000/15000 [==============================] - 1s 41us/sample - loss: 0.5005 - acc: 0.8377 - val_loss: 0.4498 - val_acc: 0.8458\n","Epoch 4/4\n","15000/15000 [==============================] - 1s 41us/sample - loss: 0.3831 - acc: 0.8745 - val_loss: 0.3701 - val_acc: 0.8634\n","25000/25000 [==============================] - 1s 46us/sample - loss: 0.3778 - acc: 0.8589\n","[0.37780490308761594, 0.85892]\n"],"name":"stdout"}]},{"metadata":{"id":"k5w5_4z8czaR","colab_type":"text"},"cell_type":"markdown","source":["## A basic Deep Learning Example #2\n","\n","A text classification task on the IMDb Dataset."]},{"metadata":{"id":"AjP5_1GHGWjp","colab_type":"code","outputId":"5c147f22-b8c0-432e-ef21-b9be1f8b10c8","executionInfo":{"status":"ok","timestamp":1555998489170,"user_tz":-180,"elapsed":124568,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":474}},"cell_type":"code","source":["'''\n","#Trains an LSTM model on the IMDB sentiment classification task.\n","The dataset is actually too small for LSTM to be of any advantage\n","compared to simpler, much faster methods such as TF-IDF + LogReg.\n","**Notes**\n","- RNNs are tricky. Choice of batch size is important,\n","choice of loss and optimizer is critical, etc.\n","Some configurations won't converge.\n","- LSTM loss decrease patterns during training can be quite different\n","from what you see with CNNs/MLPs/etc.\n","'''\n","from __future__ import print_function\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import LSTM\n","from keras.datasets import imdb\n","\n","max_features = 20000\n","# cut texts after this number of words (among top max_features most common words)\n","maxlen = 80\n","batch_size = 128\n","\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)\n","\n","print('Build model...')\n","model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=4,\n","          validation_data=(x_test, y_test))\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n","Pad sequences (samples x time)\n","x_train shape: (25000, 80)\n","x_test shape: (25000, 80)\n","Build model...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Train...\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/4\n","25000/25000 [==============================] - 28s 1ms/step - loss: 0.4795 - acc: 0.7649 - val_loss: 0.3850 - val_acc: 0.8299\n","Epoch 2/4\n","25000/25000 [==============================] - 29s 1ms/step - loss: 0.3037 - acc: 0.8784 - val_loss: 0.3741 - val_acc: 0.8346\n","Epoch 3/4\n","25000/25000 [==============================] - 27s 1ms/step - loss: 0.2387 - acc: 0.9061 - val_loss: 0.4030 - val_acc: 0.8200\n","Epoch 4/4\n","25000/25000 [==============================] - 27s 1ms/step - loss: 0.1829 - acc: 0.9328 - val_loss: 0.4440 - val_acc: 0.8208\n","25000/25000 [==============================] - 5s 218us/step\n","Test score: 0.4439715287971497\n","Test accuracy: 0.820799999961853\n"],"name":"stdout"}]},{"metadata":{"id":"K_zRgGyseTEE","colab_type":"text"},"cell_type":"markdown","source":["## A basic Deep Learning Example #3\n","\n","An image classification task on the MNIST dataset."]},{"metadata":{"id":"IwDWOGuaeHi1","colab_type":"code","outputId":"9c99a90a-7908-4c35-dec6-a94b08d8c16b","executionInfo":{"status":"ok","timestamp":1555998689227,"user_tz":-180,"elapsed":137508,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":308}},"cell_type":"code","source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","from keras.callbacks import TensorBoard\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 4\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, shuffled and split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","\n","tbCallBack = TensorBoard(histogram_freq=1,\n","                         write_graph=True,\n","                         write_grads=True,\n","                         batch_size=batch_size,\n","                         write_images=True)\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test),\n","          callbacks=[tbCallBack])\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/4\n","60000/60000 [==============================] - 7s 113us/step - loss: 0.2663 - acc: 0.9173 - val_loss: 0.0668 - val_acc: 0.9788\n","Epoch 2/4\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0902 - acc: 0.9736 - val_loss: 0.0404 - val_acc: 0.9870\n","Epoch 3/4\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0689 - acc: 0.9794 - val_loss: 0.0395 - val_acc: 0.9860\n","Epoch 4/4\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0559 - acc: 0.9838 - val_loss: 0.0307 - val_acc: 0.9900\n","Test loss: 0.030663190630599274\n","Test accuracy: 0.99\n"],"name":"stdout"}]},{"metadata":{"id":"la_XtomXekfM","colab_type":"text"},"cell_type":"markdown","source":["## A basic Deep Learning Example #4\n","\n","A text classification task on the IMDb dataset, with an attached benchmark score for the K520 GPU for batch_size equal to 30.  \n","Refer to the 'GPU Specification List'."]},{"metadata":{"id":"HuCD4WgTeieu","colab_type":"code","outputId":"ea9ba0c7-f9d2-4f89-88ff-f69a9bf5d994","executionInfo":{"status":"ok","timestamp":1555999316709,"user_tz":-180,"elapsed":219356,"user":{"displayName":"Sp Sp","photoUrl":"","userId":"10388578916492038588"}},"colab":{"base_uri":"https://localhost:8080/","height":381}},"cell_type":"code","source":["'''\n","#Train a recurrent convolutional network on the IMDB sentiment classification task.\n","Gets to 0.8498 test accuracy after 2 epochs. 41 s/epoch on K520 GPU.\n","'''\n","from __future__ import print_function\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import LSTM\n","from keras.layers import Conv1D, MaxPooling1D\n","from keras.datasets import imdb\n","\n","# Embedding\n","max_features = 20000\n","maxlen = 100\n","embedding_size = 128\n","\n","# Convolution\n","kernel_size = 5\n","filters = 64\n","pool_size = 4\n","\n","# LSTM\n","lstm_output_size = 70\n","\n","# Training\n","batch_size = 30\n","epochs = 4\n","\n","'''\n","Note:\n","batch_size is highly sensitive.\n","Only 2 epochs are needed as the dataset is very small.\n","'''\n","\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)\n","\n","print('Build model...')\n","\n","model = Sequential()\n","model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n","model.add(Dropout(0.25))\n","model.add(Conv1D(filters,\n","                 kernel_size,\n","                 padding='valid',\n","                 activation='relu',\n","                 strides=1))\n","model.add(MaxPooling1D(pool_size=pool_size))\n","model.add(LSTM(lstm_output_size))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test))\n","score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n","Pad sequences (samples x time)\n","x_train shape: (25000, 100)\n","x_test shape: (25000, 100)\n","Build model...\n","Train...\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/4\n","25000/25000 [==============================] - 51s 2ms/step - loss: 0.3867 - acc: 0.8204 - val_loss: 0.3428 - val_acc: 0.8479\n","Epoch 2/4\n","25000/25000 [==============================] - 49s 2ms/step - loss: 0.1981 - acc: 0.9249 - val_loss: 0.3454 - val_acc: 0.8568\n","Epoch 3/4\n","25000/25000 [==============================] - 49s 2ms/step - loss: 0.0947 - acc: 0.9667 - val_loss: 0.4124 - val_acc: 0.8421\n","Epoch 4/4\n","25000/25000 [==============================] - 49s 2ms/step - loss: 0.0415 - acc: 0.9856 - val_loss: 0.5811 - val_acc: 0.8409\n","25000/25000 [==============================] - 13s 534us/step\n","Test score: 0.5810983225442469\n","Test accuracy: 0.8408799942016602\n"],"name":"stdout"}]},{"metadata":{"id":"ywgUBeSbk4l5","colab_type":"text"},"cell_type":"markdown","source":["# Other Information - Not Code\n","## GPU Specifications List\n","\n","| Model | Used in Tensorflow | Generation | Memory | Bus | Shading Units | GPU Clock | Memory Clock | Theoretical FP32 | Note |\n","| - | - | - | - | - | - | - | - | - | - |\n","| Tesla T4 | Yes | Tesla | 16 GB | 256bit | 2560 | 585MHz (1590 boosted) | 10000MHz effective | 8.141 TFLOPS | |\n","| Tesla  K80 | Yes | Tesla | 12 GB x2 | 384bit x2| 2496 x2 | 562MHz (824 boosted) | 5012MHz effective | 4.113 TFLOPS x2 | The 'x2' is irrelevant, only 1 is used |\n","| Grid K520 | No | Grid K5 | 4 GB x2 | 256bit x2 | 1536 x2 | 745MHz | 5000MHz effective | 2.289 TFLOPS x2 | The 'x2' is irrelevant, only 1 is used |"]}]}