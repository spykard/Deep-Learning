{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpython36gpucondaddc583380ab244559338bc9665ae388d",
   "display_name": "Python 3.6.9 64-bit ('python36gpu': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The classic and simple LSTM on keras example, from the official repository.\n",
    "~~Train a recurrent convolutional network on the IMDB sentiment classification task.~~\n",
    "~~Baseline: gets to 0.8498 test accuracy after 2 epochs. 41 s/epoch on K520 GPU.~~\n",
    "~~batch_size is highly sensitive.~~\n",
    "~~Only 2 epochs are needed as the dataset is very small.~~\n",
    "'''\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## PARAMETERS ##\n",
    "print_tensorflow_GPU_info = True\n",
    "tensorflow_verbosity = \"INFO\"  # DEBUG(10): All | INFO(20): Info&Warning | WARN(30)[Default]: Warning | ERROR(40): Error | FATAL(50): None\n",
    "random_state = 22\n",
    "    # Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "dropout = 0.25\n",
    "    # Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "    # LSTM\n",
    "lstm_output_size = 70\n",
    "    # Training\n",
    "batch_size = 30\n",
    "epochs = 2\n",
    "loss = \"binary_crossentropy\"\n",
    "optimizer = \"adam\"\n",
    "eval_metrics = \"accuracy\"\n",
    "##             ##\n",
    "\n",
    "## Reproducibility ## \n",
    "random.seed(random_state)  # Python's seed\n",
    "np.random.seed(random_state)  # Numpy's seed\n",
    "tf.set_random_seed(random_state)  # Tensorflow's seed\n",
    "##                 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--CHANGED TENSORFLOW VERBOSITY FROM 2 (default) TO 2\n\n--AVAILABLE GPUS:\n\n--NUM OF GPUs AVAILABLE: 1\n\n--IS TF BUILT WITH CUDA: True\n\n--IS GPU AVAILABLE: True\n"
     ]
    }
   ],
   "source": [
    "## RTX GPU Memory BUG Fix & Must also be placed at the top of the code else it doesn't work ##\n",
    "from keras.backend import tensorflow_backend as K\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True                     # dynamically grow the memory used on the GPU\n",
    "#tf_config.gpu_options.per_process_gpu_memory_fraction = 0.9  # fraction of the GPU to be used\n",
    "#tf_config.log_device_placement = True                        # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=tf_config)\n",
    "K.set_session(sess)                     # set this TensorFlow session as the default session for Keras\n",
    "##                                                                                          ##     \n",
    "\n",
    "## Tensorflow Verbosity Module ##\n",
    "default_verbosity = tf.compat.v1.logging.get_verbosity()\n",
    "tf.compat.v1.logging.set_verbosity(tensorflow_verbosity)\n",
    "print(f\"\\n--CHANGED TENSORFLOW VERBOSITY FROM {default_verbosity/10:.0f} (default) TO {tf.compat.v1.logging.get_verbosity()/10:.0f}\")\n",
    "##                             ##\n",
    "\n",
    "## Tensorflow GPU Information Module ##\n",
    "if print_tensorflow_GPU_info == True:\n",
    "    print(f\"\\n--AVAILABLE GPUS:\")\n",
    "    K._get_available_gpus()\n",
    "    print(f\"\\n--NUM OF GPUs AVAILABLE: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n",
    "    print(f\"\\n--IS TF BUILT WITH CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "    print(f\"\\n--IS GPU AVAILABLE: {tf.test.is_gpu_available()}\")\n",
    "##                                   ##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Padding sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "print(f\"\\nLoading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(f\"{len(x_train)} train sequences\")\n",
    "print(f\"{len(x_test)} test sequences\")\n",
    "\n",
    "print(f\"Padding sequences (samples x time)\")\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nBuilding model...\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "print(f\"\\nBuilding model...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=[eval_metrics])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', baseline=0.70, patience=3, verbose=1)\n",
    "model_save = ModelCheckpoint('Saved Models/Introductory_text_imdb_LSTM.h5', monitor='val_loss', mode='min', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 23s 909us/step - loss: 0.3896 - accuracy: 0.8143 - val_loss: 0.3143 - val_accuracy: 0.8618\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 22s 895us/step - loss: 0.1939 - accuracy: 0.9257 - val_loss: 0.3401 - val_accuracy: 0.8563\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "print(f\"Training...\")\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stop, model_save],\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25000/25000 [==============================] - 8s 309us/step\n",
      "Test loss: 34.01125\n",
      "Test accuracy: 85.62800\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(f\"Test loss: {score*100:.5f}\")\n",
    "print(f\"Test accuracy: {acc*100:.5f}\")"
   ]
  }
 ]
}